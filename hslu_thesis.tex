\documentclass[12pt,a4paper,oneside]{report}
\usepackage{textcomp}
%--------------------------------------------------------------
% PACKAGES
%--------------------------------------------------------------
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{tocloft}
\usepackage{nomencl}
\usepackage{csquotes}
%--------------------------------------------------------------
% PAGE GEOMETRY
%--------------------------------------------------------------
\geometry{
  a4paper,
  left=3.5cm,
  right=2.5cm,
  top=2.5cm,
  bottom=2.5cm
}

%--------------------------------------------------------------
% LINE SPACING
%--------------------------------------------------------------
\onehalfspacing
\setlength{\headheight}{15pt}
%--------------------------------------------------------------
% HEADERS AND FOOTERS
%--------------------------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}

%--------------------------------------------------------------
% CHAPTER AND SECTION FORMATTING
%--------------------------------------------------------------
\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}{\chaptertitlename\ \thechapter}{20pt}{\Huge}
\titlespacing*{\chapter}{0pt}{0pt}{40pt}

%--------------------------------------------------------------
% TABLE OF CONTENTS FORMATTING
%--------------------------------------------------------------
\renewcommand{\cftchapfont}{\bfseries}
\renewcommand{\cftsecfont}{\normalfont}
\renewcommand{\cftchapleader}{\cftdotfill{\cftdotsep}}

%--------------------------------------------------------------
% NOMENCLATURE SETUP
%--------------------------------------------------------------
\makenomenclature
\renewcommand{\nomname}{Nomenclature}

%--------------------------------------------------------------
% DOCUMENT INFO
%--------------------------------------------------------------
\title{Game-Theoretic Control for Autonomous Vehicle Merging:\\
A Distributed Model Predictive Control Approach with\\
Dynamic Authority Allocation}
\author{Matan Sason}
\date{\today}
\usepackage[style=ieee, backend=biber]{biblatex}
\addbibresource{references.bib}
%--------------------------------------------------------------
% BEGIN DOCUMENT
%--------------------------------------------------------------
\begin{document}
%--------------------------------------------------------------
% TITLE PAGE
%--------------------------------------------------------------
\begin{titlepage}
\centering
\vspace*{1cm}

{\Large Ben-Gurion University of the Negev}\\[0.5cm]
{\Large Faculty of Engineering Sciences}\\[0.5cm]
{\Large Department of Mechanical Engineering}\\[2cm]

{\Huge\bfseries Game-Theoretic Control for\\[0.3cm]
Autonomous Vehicle Merging}\\[0.5cm]
{\Large A Distributed Model Predictive Control Approach with\\
Dynamic Authority Allocation}\\[3cm]

{\Large Thesis submitted in partial fulfillment of the requirements\\
for the Master of Science degree}\\[2cm]

{\Large By: Matan Sason}\\[1cm]

{\Large Under the supervision of: Shai Arogati}\\[2cm]

\vfill

{\Large \today}
\end{titlepage}

%--------------------------------------------------------------
% ABSTRACT
%--------------------------------------------------------------
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

This thesis presents a novel game-theoretic framework for merging an autonomous vehicle into a platoon using Distributed Model Predictive Control (DMPC). The merging process is formulated as a non-cooperative Nash game between the autonomous system and the human driver, where cooperative behavior emerges through dynamic authority allocation based on driving risk assessment.

The key contributions of this work include: (1) a bidirectional longitudinal safety field that quantifies collision risk from both leading and following vehicles, (2) an ellipse-based lateral safety field for lane-change scenarios, (3) a Nash equilibrium solver that computes optimal control strategies for both players, and (4) a dynamic authority allocation mechanism that smoothly transitions control from the driver to the autonomous system as risk increases.

The simulation results demonstrate that the proposed approach enables safe and comfortable merging in multiple scenarios, with significant improvements in Time-to-Collision (TTC), jerk minimization, and platoon stability relative to baseline methods.

\textbf{Keywords:} Autonomous vehicles, platoon merging, game theory, Nash equilibrium, DMPC, shared control, safety field, authority allocation

%--------------------------------------------------------------
% TABLE OF CONTENTS
%--------------------------------------------------------------
\tableofcontents
\listoffigures
\listoftables

%--------------------------------------------------------------
% NOMENCLATURE
%--------------------------------------------------------------
\printnomenclature

\nomenclature{DMPC}{Distributed Model Predictive Control}
\nomenclature{MPC}{Model Predictive Control}
\nomenclature{TTC}{Time-to-Collision}
\nomenclature{CACC}{Cooperative Adaptive Cruise Control}
\nomenclature{V2V}{Vehicle-to-Vehicle Communication}
\nomenclature{DOF}{Degrees of Freedom}

\nomenclature{$p$}{Position [m]}
\nomenclature{$v$}{Velocity [m/s]}
\nomenclature{$a$}{Acceleration [m/s$^2$]}
\nomenclature{$u_1$}{Autonomous system control input}
\nomenclature{$u_2$}{Human driver control input}
\nomenclature{$u_{\text{shared}}$}{Shared control input}
\nomenclature{$d$}{Inter-vehicle distance [m]}
\nomenclature{$v_{\text{rel}}$}{Relative velocity [m/s]}

\nomenclature{$y$}{Lateral position [m]}
\nomenclature{$\psi$}{Yaw angle [rad]}
\nomenclature{$\delta$}{Steering angle [rad]}
\nomenclature{$C_f$}{Front tire cornering stiffness [N/rad]}
\nomenclature{$C_r$}{Rear tire cornering stiffness [N/rad]}
\nomenclature{$l_a$}{Distance from CG to front axle [m]}
\nomenclature{$l_b$}{Distance from CG to rear axle [m]}

\nomenclature{$A, B_1, B_2, C$}{State-space matrices}
\nomenclature{$N_p$}{Prediction horizon}
\nomenclature{$N_u$}{Control horizon}
\nomenclature{$Q_1, Q_2$}{Output tracking weight matrices}
\nomenclature{$R_1, R_2$}{Control effort weight matrices}

\nomenclature{$\lambda$}{Authority allocation ratio}
\nomenclature{$\alpha$}{Authority parameter in shared control}
\nomenclature{$D_1, D_2$}{Control decision sequences for players 1 and 2}
\nomenclature{$J_1, J_2$}{Cost functions for players 1 and 2}
\nomenclature{$U$}{Free response prediction matrix}
\nomenclature{$H_1, H_2$}{Forced response prediction matrices}

\nomenclature{$F_{\text{risk}}$}{Risk-based repulsive force}
\nomenclature{$F_{\text{leader}}$}{Leader vehicle influence force}
\nomenclature{$F_{\text{follower}}$}{Follower vehicle influence force}

\nomenclature{$m$}{Vehicle mass [kg]}
\nomenclature{$I_z$}{Yaw moment of inertia [kg·m$^2$]}
\nomenclature{$L$}{Vehicle length [m]}

%--------------------------------------------------------------
% CHAPTER 1: INTRODUCTION (CONTINUOUS PROSE VERSION)
%--------------------------------------------------------------
\chapter{Introduction}

\section{Background}

Autonomous vehicles are becoming increasingly common on public roads. In the coming years, we expect to see both human-driven vehicles and autonomous vehicles sharing the same roads. This situation, known as mixed traffic, creates new challenges for traffic management and vehicle control systems.

One promising technology is vehicle platooning, in which a group of vehicles travels together in a coordinated manner. Platooning offers significant benefits, including reduced fuel consumption, increased road capacity, and improved safety. However, a critical challenge remains: how can a human-driven vehicle safely join an autonomous platoon?

This thesis addresses this challenge by developing a game-theoretic control framework that enables safe and comfortable merging of human-driven vehicles into autonomous platoons. The framework uses Nash equilibrium theory to balance the competing objectives of the autonomous safety system and the human driver.

\subsection{Vehicle Platooning}

Vehicle platooning is a driving formation in which multiple vehicles travel closely together at highway speeds. Vehicles maintain safe distances through coordinated control and communication. This approach offers several benefits: reduced fuel consumption through lower air resistance due to drafting effects (which can reduce fuel use by 10-15\% for following vehicles), increased road capacity through smaller following distances that allow more vehicles per kilometer of road, and improved safety through coordinated braking and communication that reduce reaction times and collision risk.

Cooperative Adaptive Cruise Control (CACC) is the technology that enables platooning \cite{treiber_traffic_2013}. CACC systems use Vehicle-to-Vehicle (V2V) communication to share information such as speed, acceleration, and braking intentions. Information sharing enables vehicles to respond more quickly than human drivers and to maintain safer following distances.

The desired spacing policy in CACC systems follows the Constant Time Gap (CTG) model \cite{rajamani_vehicle_2005}:
\begin{equation}
d_{\text{des}} = d_0 + h \cdot v
\label{eq:ctg_spacing_v2}
\end{equation}
where $d_0$ is the standstill distance (typically 5 meters), $h$ is the time headway (typically 0.8-1.2 seconds), and $v$ is the current velocity. This policy ensures that the following distance increases with speed, providing appropriate safety margins.

However, most CACC systems assume that all vehicles in the platoon are fully autonomous. This assumption does not align with the reality of mixed traffic, in which human-driven vehicles must interact with autonomous platoons. The merging of a human-driven vehicle into an autonomous platoon is a complex problem that requires careful consideration of both safety and human factors.

\subsection{Shared Control Systems}

When a human driver and an autonomous system must work together, we employ a shared-control approach. In shared control, the responsibility for driving is divided between the human and the automation system. The division of authority differs from full autonomy, in which the system has complete control, and from manual driving, in which the human has complete control.

Shared control has several important advantages. It keeps the human operator engaged in the driving task, thereby maintaining situational awareness. It provides safety assistance when the situation becomes dangerous. It allows gradual transitions between human and automated control. Finally, it respects driver autonomy while ensuring safety boundaries are maintained.

The key challenge in shared control is determining the appropriate degree of authority to assign to each party. When the situation is safe, the human should have more control to maintain engagement and respect their driving preferences. When the situation becomes dangerous, the autonomous system should assume greater control to ensure safety.

Li et al. \cite{li_shared_2019} proposed a method to dynamically adjust this authority based on the current level of driving risk. Their approach uses a safety field to quantify risk and maps this risk to an authority allocation ratio. This thesis builds upon their framework and extends it to the platoon merging problem.

\subsection{Game Theory for Vehicle Control}

Game theory is a mathematical framework for analyzing situations where multiple decision-makers interact. In the context of vehicle control, we model the human driver and the autonomous system as two players in a game. Each player has their own objectives and makes decisions to achieve those objectives.

The Nash equilibrium is a central concept in game theory. In a Nash equilibrium, no player can improve their outcome by changing only their own decision. Both players are doing the best they can, given the other player's actions. This approach makes the Nash equilibrium a stable solution for the shared control problem.

For two players with quadratic cost functions, the Nash equilibrium can be found by solving a system of coupled optimization problems using Distributed Model Predictive Control (DMPC). Player 1 (autonomous system) minimizes:
\begin{equation}
J_1 = \sum_{k=0}^{N_p-1} \|\mathbf{z}[k] - \mathbf{r}_1[k]\|_{Q_1}^2 + \|u_1[k]\|_{R_1}^2 + \|u_2[k]\|_{S_1}^2
\label{eq:cost_j1_intro}
\end{equation}

Player 2 (human driver) minimizes:
\begin{equation}
J_2 = \sum_{k=0}^{N_p-1} \|\mathbf{z}[k] - \mathbf{r}_2[k]\|_{Q_2}^2 + \|u_2[k]\|_{R_2}^2 + \|u_1[k]\|_{S_2}^2
\label{eq:cost_j2_intro}
\end{equation}

where $\mathbf{z}$ is the system output, $\mathbf{r}_i$ is each player's reference trajectory, $Q_i$ weights tracking errors, $R_i$ weights own control effort, and $S_i$ weights the other player's control effort. This formulation follows Li et al. \cite{li_shared_2019}.

An important insight from this research, which forms one of the key contributions of this thesis, is the role of the cross-coupling weights $S_1$ and $S_2$. We discovered that setting $S_i = R_i$ (cross-coupling weight equal to own control effort weight) transforms the competitive Nash game into a cooperative equilibrium. This principle, which we call the \textbf{$S = R$ Cooperation Principle}, ensures that the two controllers work together rather than against each other and is essential for achieving stable, comfortable control.

\subsection{Lane Change Trajectory Planning}

Joining a platoon requires not only longitudinal control (speed adjustment) but also lateral control (lane changing). The vehicle must change lanes to enter the platoon while avoiding collisions with the platoon vehicles.

Several approaches exist for lane change trajectory planning. Song et al. \cite{song_vehicle_2013} developed a path-planning method based on elastic band theory, in which the planned path behaves like a stretched rubber band pulled toward the target while being repelled by obstacles. While this iterative approach can handle complex obstacle configurations, it requires multiple iterations to converge and may be computationally expensive for real-time applications.

An alternative approach, which we adopt in this thesis, uses \textbf{polynomial trajectory planning}. Quintic (5th-order) polynomials yield smooth trajectories with continuous acceleration profiles, which are essential for passenger comfort. Gu and Dolan \cite{gu_toward_2014} demonstrated that polynomial-based trajectories can closely match human driving patterns in urban environments.

For smooth and comfortable lane changes, we use a quintic polynomial trajectory. The normalized progress along the trajectory is:
\begin{equation}
s(\tau) = 10\tau^3 - 15\tau^4 + 6\tau^5
\label{eq:quintic_polynomial}
\end{equation}
where $\tau = t/T_{lc}$ is the normalized time and $T_{lc}$ is the lane change duration.

This polynomial has important properties that make it suitable for vehicle control. It has zero velocity and acceleration at both endpoints, ensuring a smooth start and end. It has a continuous jerk profile, which is comfortable for passengers. It provides an analytical solution requiring no iterations, making it suitable for real-time control. The maximum lateral velocity occurs at $\tau = 0.5$, making constraint satisfaction predictable.

A key contribution of this thesis is the dynamic computation of the lane change duration $T_{lc}$ to satisfy the heading angle constraint $\psi < \psi_{\max}$. Since heading angle is approximately $\psi \approx \dot{y}/v_x$ for small angles, we can derive the minimum lane change duration:
\begin{equation}
T_{lc,\min} = \frac{1.875 \cdot |\Delta y|}{v_x \cdot \tan(\psi_{\max})}
\label{eq:T_lc_min}
\end{equation}
where $\Delta y$ is the lane change distance, $v_x$ is the longitudinal velocity, and the factor 1.875 comes from the maximum of the quintic polynomial's derivative. This constraint ensures the heading angle stays within comfortable limits (typically $\psi_{\max} < 2\SI{2}{\degree}$) throughout the maneuver.

\subsection{Safety Field Theory}

To determine when the autonomous system should intervene, we need a way to measure the current level of risk. Safety field theory, developed by Wang et al. \cite{wang_driving_2015, wang_driving_2016}, provides such a measure.

Potential-field methods inform robotics safety. The basic idea is to assign a risk value to every point around the vehicle. Areas near obstacles have high risk values, while open areas have low risk values. The total risk experienced by the vehicle depends on its position relative to surrounding obstacles.

The driving safety field consists of three components:
\begin{equation}
\mathbf{E}_s = \mathbf{E}_p + \mathbf{E}_k + \mathbf{E}_b
\label{eq:safety_field_intro}
\end{equation}
where $\mathbf{E}_p$ is the potential field from static obstacles, $\mathbf{E}_k$ is the kinetic field from moving vehicles, and $\mathbf{E}_b$ is the behavior field representing driver characteristics.

This approach has several useful properties. The risk measure is continuous, enabling smooth control responses. The method naturally handles multiple obstacles by combining their individual contributions. The resulting risk values can be used directly in the authority allocation mechanism. The field can be extended to consider both longitudinal and lateral risks.

For the platoon merging problem, we extend the safety field concept in two important ways. First, we consider bidirectional risks: the merging vehicle faces risk from both the vehicle ahead (the leader) and the vehicle behind (the follower). Second, we introduce a \textbf{phase detection system} that distinguishes between active merging (requiring aggressive safety intervention) and steady-state following (where comfort should be prioritized). This phase detection prevents oscillations that can occur when a vehicle has reached its target position, but the safety field continues to generate unnecessary corrective forces.

\section{Problem Statement}

This thesis addresses the problem of merging a human-driven vehicle into an autonomous platoon. The merging vehicle travels in a lane adjacent to the platoon and must safely enter the platoon at an appropriate position.

We decompose this problem into two subproblems, which are solved within a consistent game-theoretic framework. The first is \textbf{longitudinal control}, which regulates the vehicle's forward motion to reach and maintain the correct position within the platoon. The second is \textbf{lateral control}, which regulates lateral motion during lane changes to ensure safe entry into the platoon's lane. Both sub-problems are solved using Nash equilibrium theory with Distributed Model Predictive Control (DMPC), creating a unified control architecture.

\subsection{Longitudinal Control Problem}

The longitudinal control problem concerns the vehicle's forward motion. The goal is to adjust the vehicle's speed so that it reaches the correct position for merging and then maintains an appropriate following distance.

The specific objectives are: reaching the target position within the platoon while respecting the gap between vehicles, maintaining a safe following distance from the vehicle ahead (the leader), avoiding being hit by the vehicle behind (the follower), providing a comfortable ride by minimizing harsh acceleration, braking, and jerk, respecting the physical limits of the vehicle (maximum acceleration, maximum deceleration), and achieving real-time performance suitable for practical implementation.

This problem is challenging for several reasons. The merging vehicle must consider risks from both the front and the rear simultaneously. The vehicle must close potentially large gaps while maintaining safety. Different merging scenarios (joining at the front, middle, or rear of the platoon) require different control strategies. The transition from gap-closing to steady-state following must be smooth and stable.

\subsection{Lateral Control Problem}

The lateral control problem concerns the vehicle's lateral motion during lane changes. The goal is to guide the vehicle from its current lane into the platoon's lane.

The specific objectives are: following a smooth path to the target lane, avoiding collisions with platoon vehicles during the lane change, maintaining vehicle stability by limiting lateral acceleration and heading angle, coordinating the lane change timing with the longitudinal control, and providing comfortable steering that respects driver preferences.

This problem requires modeling the vehicle's lateral dynamics using a bicycle model, which is more complex than the double integrator used for longitudinal control. The vehicle's steering response depends on its speed and tire properties. Additionally, the human driver's behavior during lane changes varies significantly depending on their driving style (cautious, normal, or aggressive).

\subsection{Authority Allocation Problem}

When a human driver is present, we must decide how to combine the human's input with the autonomous system's commands. This is the authority allocation problem.

The shared control input is computed as:
\begin{equation}
u_{\text{shared}} = \alpha \cdot u_1 + (1 - \alpha) \cdot u_2
\label{eq:shared_control_intro}
\end{equation}
where $\alpha \in [0, 1]$ is the system authority, $u_1$ is the autonomous system's control, and $u_2$ is the human driver's control.

The authority $\alpha$ is derived from the authority ratio $\lambda$:
\begin{equation}
\alpha = \frac{\lambda}{1 + \lambda}
\label{eq:alpha_lambda}
\end{equation}

The system must estimate the human driver's intent from their driving style, assess the current risk level using the safety field, adjust the authority balance accordingly, make smooth transitions to avoid surprising the driver, and ensure the vehicle remains stable throughout all phases of operation. The authority allocation must function correctly across different driver types, from cautious drivers who prefer gentle maneuvers to aggressive drivers who prefer rapid lane changes.

\section{Research Objectives}

This thesis has the following objectives.

The first objective is to \textbf{develop an efficient Nash equilibrium solver}. We develop a Disciplined Parameterized Programming (DPP) compliant Nash solver that achieves real-time performance. The solver employs a stacked Quadratic Programming (QP) formulation that precomputes constant matrices and updates only the linear terms at each time step. This approach achieves approximately 2 milliseconds solve time, compared to 50-80 milliseconds for traditional iterative methods—a 30-fold improvement.

The second objective is to \textbf{establish the $S = R$ Cooperation Principle}. We show that setting cross-coupling weights equal to control effort weights ($S_1 = R_1$, $S_2 = R_2$) in the Nash cost functions transforms competitive behavior into cooperative behavior. This principle is essential for achieving stable, non-oscillatory control in shared control systems.

The third objective is to \textbf{develop phase-aware safety field models}. We extend safety field theory by incorporating a dynamic phase-detection system. The system distinguishes between the MERGING phase (active gap closing with aggressive safety response) and the FOLLOWING phase (steady-state operation with comfort-optimized response). Phase transitions use hysteresis to prevent oscillations, and soft transitions ensure smooth changes in control behavior.

The fourth objective is to \textbf{create a bidirectional longitudinal safety field}. We develop a safety field that accounts for risks from both the leading vehicle (ahead) and the following vehicle (behind). The field uses asymmetric weighting that reflects the information flow in CACC systems: forward-dominant coupling for string stability.

The fifth objective is to \textbf{design an ellipse-based lateral safety field}. We introduce a safety field for lateral control that employs elliptical zones around each vehicle. The ellipses are elongated in the direction of motion, reflecting the fact that more space is needed in front of a moving vehicle than beside it.

The sixth objective is to \textbf{model human driver behavior with personality types}. We create human driver models that capture individual differences in driving behavior. For longitudinal control, we use the Intelligent Driver Model (IDM) \cite{treiber_congested_2000}, which provides realistic car-following behavior with parameters for desired velocity, time headway, and comfortable acceleration. For lateral control, we use the Stanley Controller \cite{thrun_stanley_2006, abdelmoniem_path-tracking_2020}, which combines lateral error correction with heading angle alignment. Both models include personality traits (cautious, normal, and aggressive) that affect control gains and reference trajectories.

The seventh objective is to \textbf{implement unified longitudinal-lateral architecture}. We design both controllers with a consistent architecture, using the same Nash equilibrium framework with DMPC, the same phase-detection mechanism (MERGING to FOLLOWING), the same authority-allocation approach based on the safety field, and the same code structure for maintainability.

The eighth objective is to \textbf{validate through comprehensive simulation}. We test the complete system through extensive simulations that cover three merging scenarios (joining before, in the middle of, or after the platoon), three driver personality types (cautious, normal, and aggressive), and nine test cases in total, encompassing all combinations.

\section{Thesis Contributions}

This thesis makes the following contributions.

The first contribution is a \textbf{DPP-Compliant Nash Equilibrium Solver}. We develop an optimized Nash solver using Disciplined Parameterized Programming (DPP). The key innovation is to reformulate the Nash game as a single stacked QP in which the quadratic cost matrix $P$ is constant (computed once at initialization) and only the linear term $q$ updates at each time step. This enables CVXPY to cache the problem structure, achieving a solve time of approximately 2 ms (compared to 56 ms for iterative methods), combined longitudinal and lateral control in less than 4 ms total, and real-time capability at 10 Hz (longitudinal) and 50 Hz (lateral) update rates.

The second contribution is \textbf{the $S = R$ Cooperation Principle}. We discover that the relationship between cross-coupling weights ($S$) and control effort weights ($R$) fundamentally determines the nature of the Nash equilibrium. When $S < R$, controllers compete against each other, causing oscillations. When $S = R$, controllers cooperate, achieving smooth convergence. When $S > R$, controllers become overly deferential, losing effectiveness. Setting $S_1 = R_1$ and $S_2 = R_2$ ensures cooperative behavior and is essential for practical implementation.

The third contribution is \textbf{Phase Detection with Hysteresis}. We develop a dynamic phase-detection system that transitions between operating modes based on the actual system state rather than fixed timers. Entry to the FOLLOWING phase requires a gap error less than 15\% of the desired gap, a relative velocity less than 5\% of the target velocity, and all conditions stable for 5 seconds. Exit from FOLLOWING requires a gap error greater than 25\% or a relative velocity greater than 10\% (hysteresis prevents oscillation). Soft transitions provide a gradual reduction in force as errors decrease, thereby preventing sudden control changes.

The fourth contribution is a \textbf{Bidirectional Longitudinal Safety Field}. We extend the safety field concept to handle risks from both directions during platoon merging. This includes leader force (repulsive force preventing collision with vehicle ahead), follower force (weighted force maintaining safe distance from vehicle behind), asymmetric weighting (follower weight $w_f \in [0.3, 0.7]$ reflects forward-dominant CACC information flow), and dynamic adaptation (parameters adjust based on TTC, gap size, and platoon context).

The fifth contribution is \textbf{Lateral Control with Stanley-Based Human Model}. We adapt the Nash framework to lateral control using a 4-state bicycle model with states $[y, \dot{y}, \psi, \dot{\psi}]$ and proper zero-order hold discretization. We employ a Stanley controller for human-driver modeling with personality-dependent gains. Different reference trajectories are employed: a 5th-order polynomial for the system (8 seconds) and a 3rd-order polynomial for the human (5-7 seconds depending on driver type). Heading priority ($Q_\psi \gg Q_y$) ensures stability by controlling heading angle first.

The sixth contribution is a \textbf{Unified Control Architecture}. We design both longitudinal and lateral controllers with consistent structure using the same Nash/DMPC framework with DPP-compliant solvers, the same phase detection mechanism (MERGING to FOLLOWING), the same authority allocation based on safety field force, the same soft transition functions for smooth mode changes, and a multi-rate architecture (10 Hz longitudinal, 50 Hz aural).

The seventh contribution is a \textbf{Comprehensive Simulation Framework}. We develop a comprehensive Python simulation framework comprising 11 modules totaling over 5,100 lines of code, real-time visualization with trajectory plots and Nash analysis, automated testing across all 9 scenario combinations, and quantitative metrics, including collision rate (0%), TTC, jerk, and authority distribution.

\section{Thesis Organization}

The remainder of this thesis is organized as follows.

\textbf{Chapter 2: Mathematical Modeling} presents the vehicle dynamics models used in this thesis. We develop the double-integrator model for longitudinal control and the 2-DOF bicycle model for lateral control. We explain the discretization methods and the multi-rate control architecture.

\textbf{Chapter 3: Safety Field Formulations} describes the risk quantification approach. We present the bidirectional longitudinal safety field with phase detection, the ellipse-based lateral safety field, and the integration of safety fields with the Nash control framework.

\textbf{Chapter 4: Game-Theoretic Framework} presents the Nash equilibrium formulation. We describe the design of the cost function, the $S = R$ cooperation principle, the implementation of a DPP-compliant solver, and the dynamic authority allocation mechanism.

\textbf{Chapter 5: System Integration} discusses how the longitudinal and lateral controllers are combined into a unified system. We present the parallel control architecture, the controller coordination, and the complete simulation framework.

\textbf{Chapter 6: Simulation Results} presents the performance evaluation. We present results for all nine test scenarios and analyze safety metrics (collision rate, TTC), comfort metrics (jerk, lateral acceleration), and cooperation metrics (authority distribution).

\textbf{Chapter 7: Conclusions} summarizes the main findings, discusses limitations of the current work, and suggests directions for future research.


%--------------------------------------------------------------
% END OF CHAPTER 1
%--------------------------------------------------------------
%--------------------------------------------------------------
% CHAPTER 2: MATHEMATICAL MODELING
%--------------------------------------------------------------
\chapter{Mathematical Modeling}

\section{Introduction}

This chapter presents the mathematical models of vehicle dynamics used in this thesis. The control system requires accurate yet computationally efficient models that can run in real-time. We develop two separate models: a longitudinal model for forward motion control and a lateral model for steering control during lane changes.

The longitudinal model employs a double-integrator representation that captures the essential relationship among acceleration, velocity, and position. This simple model is sufficient for platoon control because the primary dynamics of interest are the spacing and speed relationships between vehicles.

The lateral model employs a bicycle model representation that captures the vehicle's response to steering inputs. This model accounts for tire slip angles and vehicle inertia, which are important for accurate lane-change trajectory tracking.

Both models are converted from continuous time to discrete time using a Zero-Order Hold (ZOH) discretization. This conversion is necessary because the control algorithms operate at fixed time intervals. The ZOH method assumes that the control input remains constant between sampling instants, which is consistent with the behavior of digital control systems.

\section{Longitudinal Vehicle Model}

\subsection{Continuous-Time Representation}

Newton's second law can describe the longitudinal motion of a vehicle. The vehicle's acceleration is given by the net force acting on it divided by its mass. For control purposes, we treat acceleration as the control input, thereby simplifying the model while retaining the essential dynamics.

The state vector for the longitudinal model consists of position and velocity:
\begin{equation}
\mathbf{x} = \begin{bmatrix} x \\ v_x \end{bmatrix}
\label{eq:long_state}
\end{equation}
where $x$ is the longitudinal position in meters and $v_x$ is the longitudinal velocity in meters per second.

The continuous-time state-space representation is:
\begin{equation}
\dot{\mathbf{x}} = A_c \mathbf{x} + B_c u
\label{eq:long_continuous}
\end{equation}
where the state matrix and input matrix are:
\begin{equation}
A_c = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix}, \quad
B_c = \begin{bmatrix} 0 \\ 1 \end{bmatrix}
\label{eq:long_matrices_continuous}
\end{equation}

The control input $u$ is the longitudinal acceleration $a_x$ in meters per second squared. The output equation is:
\begin{equation}
\mathbf{y} = C \mathbf{x} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \mathbf{x}
\label{eq:long_output}
\end{equation}
which means both position and velocity are available as outputs.

This model is known as a double integrator because integrating acceleration yields velocity, and integrating velocity yields position. The double integrator is a fundamental building block in control theory and has well-understood properties \cite{rajamani_vehicle_2005}.

\subsection{Discrete-Time Representation}

For digital implementation, we convert the continuous-time model to discrete time using a Zero-Order Hold (ZOH) discretization. The ZOH method assumes that the control input remains constant during each sampling interval $\Delta t$.

The discrete-time state equation is:
\begin{equation}
\mathbf{x}[k+1] = A_d \mathbf{x}[k] + B_d u[k]
\label{eq:long_discrete}
\end{equation}

For the double-integrator system, ZOH discretization yields analytical expressions for the discrete matrices. The discrete state matrix is obtained from the matrix exponential:
\begin{equation}
A_d = e^{A_c \Delta t} = \begin{bmatrix} 1 & \Delta t \\ 0 & 1 \end{bmatrix}
\label{eq:Ad_long}
\end{equation}

The discrete input matrix is:
\begin{equation}
B_d = \int_0^{\Delta t} e^{A_c \tau} d\tau \cdot B_c = \begin{bmatrix} \frac{\Delta t^2}{2} \\ \Delta t \end{bmatrix}
\label{eq:Bd_long}
\end{equation}

These matrices have a clear physical interpretation. The state update equation expands to:
\begin{align}
x[k+1] &= x[k] + v_x[k] \cdot \Delta t + \frac{1}{2} a_x[k] \cdot \Delta t^2 \label{eq:pos_update} \\
v_x[k+1] &= v_x[k] + a_x[k] \cdot \Delta t \label{eq:vel_update}
\end{align}

These are the standard kinematic equations for motion with constant acceleration during each time step. The position update includes the $\frac{1}{2} a_x \Delta t^2$ term, which accounts for the fact that the velocity changes during the interval. This term is often omitted in simpler Euler discretization methods, but the ZOH method correctly captures this effect.

\subsection{Control Constraints}

Physical vehicles have limits on their acceleration and deceleration capabilities. We impose the following constraints on the control input:
\begin{equation}
a_{\min} \leq u \leq a_{\max}
\label{eq:accel_constraints}
\end{equation}
where typical values are $a_{\min} = -3.0$ m/s² (comfortable braking) and $a_{\max} = 2.5$ m/s² (moderate acceleration).

For passenger comfort, we also consider jerk constraints. Jerk is the rate of change of acceleration:
\begin{equation}
j = \frac{da_x}{dt} \approx \frac{a_x[k] - a_x[k-1]}{\Delta t}
\label{eq:jerk}
\end{equation}

Comfortable jerk limits are typically $|j| \leq 2.0$ m/s³ for normal driving and $|j| \leq 5.0$ m/s³ for emergency maneuvers.

\subsection{Sampling Rate Selection}

The longitudinal controller operates at a sampling rate of 10 Hz ($\Delta t = 0.1$ seconds). This rate is chosen based on several considerations. First, it is fast enough to capture the relevant dynamics of vehicle following, where typical time constants are on the order of 1-2 seconds. Second, it provides sufficient time for the optimization solver to compute the control input. Third, it matches typical update rates used in commercial adaptive cruise control systems.

At 10 Hz, the discrete matrices become:
\begin{equation}
A_d = \begin{bmatrix} 1 & 0.1 \\ 0 & 1 \end{bmatrix}, \quad
B_d = \begin{bmatrix} 0.005 \\ 0.1 \end{bmatrix}
\label{eq:Ad_Bd_10Hz}
\end{equation}

\section{Lateral Vehicle Model}

\subsection{The Bicycle Model}

For lateral dynamics, we use a simplified vehicle model known as the bicycle model or single-track model \cite{rajamani_vehicle_2005}. This model combines the two front wheels into a single wheel at the front axle centerline, and similarly for the rear wheels. The bicycle model is widely used in vehicle dynamics and control because it captures the essential lateral behavior while remaining computationally tractable.

The bicycle model assumptions are: the vehicle moves on a flat, horizontal surface; the left and right tire forces are combined into single forces at each axle; tire slip angles are small enough that the lateral force is proportional to slip angle (linear tire model); and the vehicle's roll and pitch motions are neglected.

\subsection{State Variables}

The state vector for the lateral model consists of four variables:
\begin{equation}
\mathbf{x} = \begin{bmatrix} y \\ \dot{y} \\ \psi \\ \dot{\psi} \end{bmatrix}
\label{eq:lat_state}
\end{equation}
where $y$ is the lateral position (perpendicular to the road centerline) in meters, $\dot{y}$ is the lateral velocity in meters per second, $\psi$ is the heading angle (yaw angle relative to the road) in radians, and $\dot{\psi}$ is the yaw rate in radians per second.

\subsection{Continuous-Time Equations}

The equations of motion for the bicycle model are derived from Newton's second law for lateral translation and rotation \cite{rajamani_vehicle_2005, hoffmann_autonomous_2007}:
\begin{align}
m \ddot{y} &= F_{yf} + F_{yr} \label{eq:lat_force} \\
I_z \ddot{\psi} &= a F_{yf} - b F_{yr} \label{eq:yaw_moment}
\end{align}
where $m$ is the vehicle mass, $I_z$ is the yaw moment of inertia, $F_{yf}$ and $F_{yr}$ are the lateral tire forces at the front and rear axles, and $a$ and $b$ are the distances from the center of gravity to the front and rear axles, respectively.

For small slip angles, the tire forces are proportional to the slip angles:
\begin{align}
F_{yf} &= -C_f \alpha_f \label{eq:front_tire} \\
F_{yr} &= -C_r \alpha_r \label{eq:rear_tire}
\end{align}
where $C_f$ and $C_r$ are the cornering stiffnesses of the front and rear tires, and $\alpha_f$ and $\alpha_r$ are the front and rear slip angles.

The slip angles depend on the vehicle's motion and the steering angle:
\begin{align}
\alpha_f &= \frac{\dot{y} + a \dot{\psi}}{v_x} - \delta \label{eq:front_slip} \\
\alpha_r &= \frac{\dot{y} - b \dot{\psi}}{v_x} \label{eq:rear_slip}
\end{align}
where $\delta$ is the front wheel steering angle and $v_x$ is the longitudinal velocity.

Substituting and rearranging, the state-space representation becomes:
\begin{equation}
\dot{\mathbf{x}} = A_c \mathbf{x} + B_c \delta
\label{eq:lat_ss_continuous}
\end{equation}
where the state matrix is:
\begin{equation}
A_c = \begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & -\frac{C_f + C_r}{m v_x} & 0 & \frac{-v_x - \frac{a C_f - b C_r}{m v_x}}{1} \\
0 & 0 & 0 & 1 \\
0 & -\frac{a C_f - b C_r}{I_z v_x} & 0 & -\frac{a^2 C_f + b^2 C_r}{I_z v_x}
\end{bmatrix}
\label{eq:Ac_lat}
\end{equation}

The input matrix is:
\begin{equation}
B_c = \begin{bmatrix} 0 \\ \frac{C_f}{m} \\ 0 \\ \frac{a C_f}{I_z} \end{bmatrix}
\label{eq:Bc_lat}
\end{equation}

Note that the state matrix $A_c$ depends on the longitudinal velocity $v_x$. This means that strictly speaking, the lateral model is a linear parameter-varying (LPV) system. For the MPC implementation, we update the matrices at each time step using the current velocity.

\subsection{Discrete-Time Representation}

The continuous-time lateral model is converted to discrete-time using ZOH discretization. Unlike the double integrator, the bicycle model does not have simple analytical expressions for the discrete matrices. Instead, we compute them numerically using the matrix exponential method.

The discrete state matrix is:
\begin{equation}
A_d = e^{A_c \Delta t}
\label{eq:Ad_lat}
\end{equation}

The discrete input matrix is computed using the augmented matrix method:
\begin{equation}
\begin{bmatrix} A_d & B_d \\ 0 & I \end{bmatrix} = \exp\left( \begin{bmatrix} A_c & B_c \\ 0 & 0 \end{bmatrix} \Delta t \right)
\label{eq:augmented}
\end{equation}

This method is implemented using the \texttt{scipy.linalg.expm} function in Python, which computes the matrix exponential using a Padé approximation with scaling and squaring.

\subsection{Vehicle Parameters}

The bicycle model parameters used in this thesis are based on a typical passenger vehicle \cite{rajamani_vehicle_2005, fernandez_vehicle_nodate}. The vehicle mass is $m = 1500$ kg. The yaw moment of inertia is $I_z = 2500$ kg·m². The distance from the center of gravity to the front axle is $a = 1.2$ m. The distance from the center of gravity to the rear axle is $b = 1.4$ m. The total wheelbase is $L = a + b = 2.6$ m. The front cornering stiffness is $C_f = 80000$ N/rad. The rear cornering stiffness is $C_r = 80000$ N/rad.

These parameters correspond to a front-wheel-drive sedan with a slightly rear-biased weight distribution, typical of vehicles with the engine in front.

\subsection{Sampling Rate Selection}

The lateral controller operates at a sampling rate of 50 Hz ($\Delta t = 0.02$ seconds). This higher rate compared to the longitudinal controller is necessary because the lateral dynamics have faster time constants. Yaw dynamics, in particular, can change rapidly, especially at higher speeds.

At highway speeds (30 m/s), the characteristic time constants of the bicycle model are approximately 0.1-0.3 seconds. The 50 Hz sampling rate provides 5-15 samples per time constant, which is sufficient for accurate control.

\section{Multi-Rate Control Architecture}

The longitudinal and lateral controllers operate at different rates: 10 Hz for longitudinal and 50 Hz for lateral. This multi-rate architecture is implemented as follows.

Both controllers run in parallel. The longitudinal controller updates every 100 ms to compute a new acceleration command. The lateral controller updates every 20 ms to compute a new steering command. Between longitudinal updates, the lateral controller uses the most recent acceleration command from the longitudinal controller.

The controllers share state information through the vehicle state vector, which is updated at the faster rate (50 Hz). This ensures that both controllers have access to the most recent position, velocity, and heading information.

The multi-rate architecture has several advantages. It allows each controller to operate at a rate appropriate for its dynamics. It reduces computational load by avoiding unnecessary high rates of longitudinal optimization. It aligns with the typical architecture of production vehicle control systems, in which different subsystems operate at different rates.

\section{Human Driver Models}

\subsection{Longitudinal: Intelligent Driver Model}

To model the human driver's longitudinal behavior, we use the Intelligent Driver Model (IDM) developed by Treiber et al. \cite{treiber_congested_2000, treiber_traffic_2013}. The IDM is a car-following model that produces realistic acceleration behavior based on the current velocity, the gap to the leading vehicle, and the relative velocity.

The IDM acceleration is given by:
\begin{equation}
a_{\text{IDM}} = a_{\max} \left[ 1 - \left( \frac{v}{v_0} \right)^\delta - \left( \frac{s^*(v, \Delta v)}{s} \right)^2 \right]
\label{eq:idm}
\end{equation}
where $a_{\max}$ is the maximum acceleration, $v$ is the current velocity, $v_0$ is the desired velocity, $s$ is the current gap, $\delta$ is the acceleration exponent (typically 4), and $s^*$ is the desired gap given by:
\begin{equation}
s^*(v, \Delta v) = s_0 + v T + \frac{v \Delta v}{2 \sqrt{a_{\max} b}}
\label{eq:idm_desired_gap}
\end{equation}
where $s_0$ is the minimum gap at standstill, $T$ is the desired time headway, $\Delta v$ is the velocity difference to the leading vehicle, and $b$ is the comfortable deceleration.

The IDM parameters are adjusted based on driver personality type: cautious drivers exhibit larger time headways and lower maximum accelerations, whereas aggressive drivers exhibit smaller time headways and higher maximum accelerations.

\subsection{Lateral: Stanley Controller}

To model the human driver's lateral behavior during lane changes, we use the Stanley controller \cite{thrun_stanley_2006, abdelmoniem_path-tracking_2020}. The Stanley controller was developed for the Stanford Racing Team's autonomous vehicle and is known for producing smooth, human-like steering behavior.

The Stanley steering command is:
\begin{equation}
\delta = \psi_e + \arctan\left( \frac{k_e \cdot e}{v_x} \right)
\label{eq:stanley}
\end{equation}
where $\psi_e$ is the heading error relative to the path, $e$ is the cross-track error (lateral distance from the path), $k_e$ is the cross-track gain, and $v_x$ is the longitudinal velocity.

The Stanley controller combines two correction terms. The first term ($\psi_e$) corrects the heading to align with the path. The second term corrects the lateral position, with the $\arctan$ function ensuring that the correction is bounded even for large errors. The velocity in the denominator indicates that at higher speeds, smaller steering corrections are required to achieve the same lateral error, which aligns with human driving behavior.

As shown by Hoffmann et al. \cite{hoffmann_autonomous_2007}, the Stanley controller is globally asymptotically stable for path following, meaning that the vehicle converges to the desired path from any initial condition.

\subsection{Driver Personality Types}

We model three types of human drivers with different parameter settings. The cautious driver has IDM time headway $T = 2.0$ s, comfortable deceleration $b = 1.5$ m/s², and Stanley gain $k_e = 1.5$. The normal driver has an IDM time headway $T = 1.5$ s, a comfortable deceleration $b = 2.0$ m/s², and a Stanley gain $k_e = 2.5$. The aggressive driver has IDM time headway $T = 1.0$ s, comfortable deceleration $b = 2.5$ m/s², and Stanley gain $k_e = 3.5$.

These personality types affect the reference trajectories generated for the human driver in the Nash game formulation. A cautious driver's reference will exhibit larger gaps and slower lane changes, whereas an aggressive driver's reference will exhibit smaller gaps and faster lane changes.

\section{Summary}

This chapter presented the mathematical models used for vehicle dynamics in this thesis. The longitudinal model is a double integrator with state variables for position and velocity, discretized at 10 Hz using ZOH. The lateral model is a 4-state bicycle model capturing lateral position, lateral velocity, heading, and yaw rate, discretized at 50 Hz using ZOH.

Both models are formulated in state-space form suitable for Model Predictive Control. The discrete-time formulations enable efficient implementation in the Nash equilibrium solver described in Chapter 4.

Human driver behavior is modeled using the Intelligent Driver Model for longitudinal control and the Stanley Controller for lateral control. Three personality types (cautious, normal, and aggressive) are defined through different parameter settings.

The multi-rate architecture allows each controller to operate at a rate appropriate for its dynamics while sharing state information through a common vehicle state vector.

%--------------------------------------------------------------
% END OF CHAPTER 2
%--------------------------------------------------------------
%--------------------------------------------------------------
% CHAPTER 3: SAFETY FIELD FORMULATIONS (REVISED)
% Aligned with actual code implementation
% Version: February 2026
% Format: Academic prose without bullet points
%--------------------------------------------------------------
\chapter{Safety Field Formulations}

This chapter presents the mathematical framework for quantifying collision risk in both longitudinal and lateral directions. The safety field approach provides continuous risk measures that integrate seamlessly with the Nash equilibrium control framework through dynamic authority allocation. A key innovation in this work is the \textbf{dynamic phase detection system} that distinguishes between active merging and steady-state following phases, enabling context-appropriate control responses.

Section 3.1 introduces the theoretical foundation of driving safety field theory. Section 3.2 describes the bidirectional longitudinal safety field with phase detection. Section 3.3 presents the collision-based lateral safety field. Section 3.4 discusses integration with the Nash control framework.

\section{Driving Safety Field Theory - Overview}

The Driving Safety Field theory \cite{wang_driving_2015, wang_driving_2016} extends potential field methods from robotics to automotive applications, representing collision risk as a continuous field. Following Li et al. \cite{li_shared_2019}, the total driving safety field comprises three components as shown in Equation \ref{eq:total_safety_field}:

\begin{equation}
\mathbf{E}_s = \mathbf{E}_p + \mathbf{E}_k + \mathbf{E}_b
\label{eq:total_safety_field}
\end{equation}

where $\mathbf{E}_p$ is the potential field representing static obstacles, $\mathbf{E}_k$ is the kinetic field representing moving vehicles, and $\mathbf{E}_b$ is the behavior field capturing driver characteristics. In platoon-merging applications, the kinetic field dominates the total field.

The field strength translates to a control force according to:

\begin{equation}
\mathbf{F}_{fi} = E_{si} M_i R_i \exp(-k_2 v_i \cos \theta_i) (1 + DR_i)
\label{eq:field_force}
\end{equation}

where $M_i$ is vehicle virtual mass, $R_i$ is the road condition factor, $v_i$ is velocity, and $DR_i$ is the driver risk factor.

\subsection{Design Philosophy: Pure Repulsive Forces}

A fundamental design decision in this implementation is the use of \textbf{pure repulsive forces}. Unlike classical potential field methods that employ both attractive and repulsive components, our safety field generates force only when actual collision risk exists:

\begin{equation}
F_{\text{safety}}(d) = \begin{cases}
f(d) > 0 & \text{if } d < d_{\text{safe}} \text{ (danger zone)} \\
0 & \text{if } d \geq d_{\text{safe}} \text{ (safe zone)}
\end{cases}
\label{eq:pure_repulsive}
\end{equation}

This approach offers several advantages. First, the Nash equilibrium solver handles trajectory tracking without interference from the safety system when no danger exists. Second, there is a clear separation of concerns, with Nash providing optimal tracking while the safety field prevents collisions. Third, reduced oscillations are observed compared with systems with competing attractive forces. Fourth, computational efficiency is achieved through sparse force calculations.

\section{Bidirectional Longitudinal Safety Field}

\subsection{Overview and Architecture}

The longitudinal safety field addresses the unique challenge of platoon merging, where the ego vehicle faces threats from both the leader vehicle ahead and the follower vehicle behind. The implementation uses a \textbf{pure repulsive} approach where forces are generated only when the gap to a neighboring vehicle falls below the desired safe distance.

The core principle follows the gap error formulation:
\begin{equation}
e_{\text{gap}} = d_{\text{actual}} - d_{\text{desired}}
\label{eq:gap_error}
\end{equation}

where $d_{\text{actual}}$ is the current inter-vehicle gap and $d_{\text{desired}}$ is the target following distance. When $e_{\text{gap}} > 0$, the vehicle is safe and no repulsive force is generated. When $e_{\text{gap}} < 0$, the vehicle is too close, and the repulsive force increases.

\subsection{Force Computation Model}

The repulsive force from the leader vehicle is computed using an ellipse-based potential field inspired by Li et al. \cite{li_shared_2019}:

\begin{equation}
F_{\text{leader}} = \frac{M_o \cdot R_i}{(r_e + \epsilon)^2} \cdot w_d \cdot w_v \cdot (1 + DR_i)
\label{eq:leader_force_impl}
\end{equation}

where the components are defined as follows.

\textbf{Elliptic distance ratio:}
\begin{equation}
r_e = \frac{|e_{\text{gap}}|}{s + \epsilon}
\label{eq:elliptic_ratio}
\end{equation}

where $s$ is the dynamic safety radius and $\epsilon = 0.1$ m prevents singularities.

\textbf{Distance decay weight:}
\begin{equation}
w_d = \exp\left(-\frac{|e_{\text{gap}}|}{\tau_d}\right)
\label{eq:distance_decay}
\end{equation}

with decay factor $\tau_d = 15$ m, ensuring force diminishes smoothly with distance.

\textbf{Velocity-dependent weight:}
\begin{equation}
w_v = \exp\left(\frac{\max(0, v_{\text{rel}})}{5.0}\right)
\label{eq:velocity_weight}
\end{equation}

where $v_{\text{rel}} = v_{\text{ego}} - v_{\text{leader}}$ is the closing velocity. This term amplifies the force experienced when approaching the leader at a positive relative velocity.

\textbf{Behavior factor:}
\begin{equation}
w_b = 1 + DR_i
\label{eq:behavior_factor}
\end{equation}

where $DR_i$ is the dynamic driving risk factor with baseline value 0.5.

\subsection{Dynamic Parameter Computation}

All safety field parameters are adapted to the current driving context via low-pass-filtered updates.

\subsubsection{Dynamic Safety Radius}

The safety radius expands or contracts based on vehicle position in the platoon and current velocity:

\begin{equation}
s = s_{\text{base}} \cdot m_{\text{pos}} \cdot \left(1 + \alpha_v \cdot \frac{v_{\text{ego}}}{v_{\text{ref}}} - \alpha_v\right)
\label{eq:dynamic_radius_impl}
\end{equation}

where $s_{\text{base}} = 10$ m is the base safety radius, $\alpha_v = 0.8$ is the velocity scaling factor, and $v_{\text{ref}} = 120$ m/s is the reference velocity. The position multiplier $m_{\text{pos}}$ takes values of 0.8 when the ego vehicle is at the front of the platoon in the leader position, 1.2 when the ego is in the middle of the platoon, and 1.0 when the ego is at the back in the follower position:

\begin{equation}
m_{\text{pos}} = \begin{cases}
0.8 & \text{ego at front of platoon (leader position)} \\
1.2 & \text{ego in middle of platoon} \\
1.0 & \text{ego at back of platoon (follower position)}
\end{cases}
\label{eq:position_multiplier}
\end{equation}

The velocity scaling ensures that higher speeds yield larger safety zones, consistent with the intuition that faster vehicles require greater reaction distance.

\subsubsection{Dynamic Obstacle Mass}

The virtual obstacle mass follows a similar pattern:
\begin{equation}
M_o = M_{\text{base}} \cdot m_{\text{pos}}
\label{eq:dynamic_mass}
\end{equation}

where $M_{\text{base}} = 400$ kg equivalent.

\subsubsection{Low-Pass Filtering}

To prevent abrupt parameter changes that could cause control discontinuities, all dynamic parameters are filtered:

\begin{equation}
\theta_{\text{filtered}}[k] = \alpha_f \cdot \theta_{\text{target}}[k] + (1 - \alpha_f) \cdot \theta_{\text{filtered}}[k-1]
\label{eq:lowpass_filter}
\end{equation}

where $\alpha_f = 0.2$ is the filter coefficient, providing smooth transitions while remaining responsive to changing conditions.

\subsection{Bidirectional Force Combination}

The total longitudinal safety force combines leader and follower contributions:

\begin{equation}
F_{\text{total}} = F_{\text{leader}} + w_f \cdot F_{\text{follower}}
\label{eq:bidirectional_force}
\end{equation}

The follower weight $w_f$ reflects the asymmetric information flow in Cooperative Adaptive Cruise Control (CACC) systems, where information primarily flows forward from leader to follower. The weight takes the value 0.5 during normal operation, 0.2 when the follower is joining and is far behind, and 0.4 when the follower is decelerating:

\begin{equation}
w_f = \begin{cases}
0.5 & \text{normal operation} \\
0.2 & \text{follower is joining (far behind)} \\
0.4 & \text{follower is decelerating}
\end{cases}
\label{eq:follower_weight_impl}
\end{equation}

This forward-dominant weighting ensures string stability by preventing the ego vehicle from over-reacting to follower dynamics.

\subsection{Phase Detection System}

A key innovation in this work is the \textbf{dynamic phase detection system} that distinguishes between operating modes based on actual system state rather than fixed timers. This prevents the safety field from generating unnecessary corrective forces once the vehicle has reached steady-state following.

\subsubsection{Control Phases}

The system operates in two primary phases. The first is the \textbf{MERGING Phase}, which involves active gap closing with full safety field response, where the vehicle is actively approaching its target position in the platoon. The second is the \textbf{FOLLOWING Phase}, which represents steady-state operation with soft-transition response, where the vehicle has reached its target position and maintains formation.

\subsubsection{Phase Transition Conditions}

\textbf{Entry to FOLLOWING Phase} requires all conditions to be satisfied simultaneously for a sustained period:

\begin{align}
|e_{\text{gap}}| &< \gamma_{\text{gap}} \cdot d_{\text{desired}} \label{eq:following_gap} \\
|v_{\text{rel}}| &< \gamma_v \cdot v_{\text{target}} \label{eq:following_vel} \\
|a_{\text{ego}}| &< a_{\text{threshold}} \label{eq:following_acc}
\end{align}

where $\gamma_{\text{gap}} = 0.15$ represents 15\% of the desired gap, $\gamma_v = 0.05$ represents 5\% of target velocity, $a_{\text{threshold}} = 0.5$ m/s², and all conditions must hold for $T_{\text{stable}} = 5$ seconds.

\textbf{Exit from FOLLOWING Phase} occurs immediately if any threshold is violated:

\begin{align}
|e_{\text{gap}}| &> \gamma_{\text{gap,exit}} \cdot d_{\text{desired}} \quad \text{OR} \label{eq:merging_gap} \\
|v_{\text{rel}}| &> \gamma_{v,\text{exit}} \cdot v_{\text{target}} \label{eq:merging_vel}
\end{align}

where $\gamma_{\text{gap,exit}} = 0.25$ provides 25\% hysteresis and $\gamma_{v,\text{exit}} = 0.10$ provides 10\% hysteresis.

The hysteresis between entry and exit thresholds (15\% vs 25\% for gap, 5\% vs 10\% for velocity) prevents oscillation between phases.

\subsubsection{Soft Transition Function}

In the FOLLOWING phase, forces are scaled by a quadratic soft transition function:

\begin{equation}
F_{\text{following}} = F_{\text{raw}} \cdot \min\left(1.0, \left(\frac{|e_{\text{gap}}|}{\gamma_{\text{gap}} \cdot d_{\text{desired}}}\right)^2\right)
\label{eq:soft_transition}
\end{equation}

This creates a smooth reduction of force as the gap error decreases. At the threshold where $|e_{\text{gap}}| = \gamma_{\text{gap}} \cdot d_{\text{desired}}$, the force is at 100\%. At 50\% of the threshold, the force drops to 25\%. Near zero error, the force becomes negligible.

The quadratic relationship ensures smooth, jerk-free transitions while maintaining safety responsiveness for larger errors.

\subsection{Target Position Locking}

After the merge is triggered at time $t_{\text{merge}}$, the safety field locks onto specific leader and follower vehicles by their identifiers rather than using dynamic closest-vehicle detection. This prevents target switching during the merge maneuver:

\begin{equation}
\text{target}_{\text{leader}} = \begin{cases}
\text{closest vehicle ahead} & t < t_{\text{merge}} \\
\text{locked ID} & t \geq t_{\text{merge}}
\end{cases}
\label{eq:target_locking}
\end{equation}

This mechanism is essential for stable merging behavior, especially in scenarios where the ego vehicle may temporarily come closer to a different platoon member than its intended target.

\subsection{Force Saturation and Output}

The final force output is saturated to prevent excessive control commands:

\begin{equation}
F_{\text{output}} = \text{clip}(F_{\text{total}}, -500, 800) \text{ N}
\label{eq:force_saturation}
\end{equation}

The asymmetric limits reflect that stronger acceleration intervention may be needed (positive force for braking when too close to the leader) compared to negative force (accelerating when the follower is too close).

\subsection{Implementation Algorithm}

Algorithm \ref{alg:longitudinal_field_impl} summarizes the complete longitudinal safety field computation.

\begin{algorithm}[H]
\caption{Bidirectional Longitudinal Safety Field with Phase Detection}
\label{alg:longitudinal_field_impl}
\begin{algorithmic}[1]
\State \textbf{Input:} Ego state $(x_e, v_e, a_e)$, Leader $(x_l, v_l)$, Follower $(x_f, v_f)$, $d_{\text{desired}}$, $t$
\State \textbf{Output:} Total force $F_{\text{total}}$

\State // Update phase based on conditions
\State $e_{\text{gap}} \gets (x_l - x_e) - d_{\text{desired}}$
\State $v_{\text{rel}} \gets v_e - v_l$
\State Call \textsc{UpdatePhase}($e_{\text{gap}}$, $v_{\text{rel}}$, $a_e$, $d_{\text{desired}}$, $v_{\text{target}}$)

\State // Compute leader force (only if gap < desired)
\If{$e_{\text{gap}} < 0$}
    \State $s \gets$ \textsc{ComputeDynamicRadius}(context)
    \State $M_o \gets$ \textsc{ComputeDynamicMass}(context)
    \State $r_e \gets |e_{\text{gap}}| / (s + \epsilon)$
    \State $w_d \gets \exp(-|e_{\text{gap}}| / \tau_d)$
    \State $w_v \gets \exp(\max(0, v_{\text{rel}}) / 5.0)$
    \State $F_{\text{leader}} \gets M_o \cdot R_i / (r_e + \epsilon)^2 \cdot w_d \cdot w_v \cdot (1 + DR_i)$
\Else
    \State $F_{\text{leader}} \gets 0$ \Comment{Safe - no force needed}
\EndIf

\State // Compute follower force with adaptive weight
\If{follower exists AND not ignoring follower}
    \State $w_f \gets$ \textsc{GetFollowerWeight}(context)
    \State $F_{\text{follower}} \gets w_f \cdot$ \textsc{ComputeForce}(follower)
\Else
    \State $F_{\text{follower}} \gets 0$
\EndIf

\State // Apply soft transition in FOLLOWING phase
\If{phase = FOLLOWING}
    \State $F_{\text{leader}} \gets$ \textsc{ApplySoftTransition}($F_{\text{leader}}$, $e_{\text{gap}}$, $d_{\text{desired}}$)
    \State $F_{\text{follower}} \gets$ \textsc{ApplySoftTransition}($F_{\text{follower}}$, $e_{\text{gap,f}}$, $d_{\text{desired}}$)
\EndIf

\State $F_{\text{total}} \gets F_{\text{leader}} + F_{\text{follower}}$
\State $F_{\text{total}} \gets \text{clip}(F_{\text{total}}, -500, 800)$
\State \Return $F_{\text{total}}$
\end{algorithmic}
\end{algorithm}

\section{Collision-Based Lateral Safety Field}

\subsection{Design Philosophy}

The lateral safety field addresses collision avoidance during lane change maneuvers. A critical design insight distinguishes this implementation from the longitudinal field.

\textbf{Key Difference:} In longitudinal control, approaching the leader (reducing the gap) is dangerous. In lateral control, approaching the target lane is \textit{desired behavior}, not danger. Therefore, the lateral safety field generates force only from \textit{actual proximity to other vehicles}, not from approaching the target lane.

This collision-based approach ensures that the Nash equilibrium can freely control the lane change trajectory, that safety intervention occurs only when collision risk is genuine, and that there is no interference with normal lane change execution.

\subsection{Control Phases for Lateral Motion}

The lateral controller uses a five-phase state machine. The \textbf{CRUISE} phase represents normal lane keeping while waiting for the merge command. The \textbf{GAP\_SEARCH} phase involves searching for a suitable gap in the target lane. The \textbf{LANE\_CHANGE} phase is the active lane change execution. The \textbf{LANE\_KEEPING} phase involves stabilizing in the target lane. Finally, the \textbf{FOLLOWING} phase represents steady-state lateral control.

Phase transitions follow similar logic to longitudinal control, with conditions adapted for lateral dynamics.

\textbf{Entry to FOLLOWING:}
\begin{align}
|y_{\text{error}}| &< \gamma_y \cdot W_{\text{lane}} \label{eq:lat_following_y} \\
|\psi| &< \psi_{\text{threshold}} \label{eq:lat_following_psi} \\
|\dot{y}| &< \dot{y}_{\text{threshold}} \label{eq:lat_following_ydot}
\end{align}

where $\gamma_y = 0.15$, $W_{\text{lane}} = 3.5$ m, $\psi_{\text{threshold}} = 0.05$ rad (approximately 3\SI{2}{\degree}), and $\dot{y}_{\text{threshold}} = 0.3$ m/s, all sustained for 5 seconds.

\textbf{Exit from FOLLOWING:}
\begin{align}
|y_{\text{error}}| &> 0.25 \cdot W_{\text{lane}} \quad \text{OR} \label{eq:lat_merging_y} \\
|\psi| &> 0.10 \text{ rad} \label{eq:lat_merging_psi}
\end{align}

\subsection{Collision Detection and Force Computation}

The lateral safety field uses a two-threshold system for collision detection:

\begin{equation}
\text{Collision Risk} = \begin{cases}
\text{None} & |d_y| > d_{\text{safe}} \\
\text{Low} & d_{\text{collision}} < |d_y| \leq d_{\text{safe}} \\
\text{High} & |d_y| \leq d_{\text{collision}}
\end{cases}
\label{eq:collision_zones}
\end{equation}

where $d_y$ is the lateral distance to the obstacle, $d_{\text{safe}} = 3.0$ m, and $d_{\text{collision}} = 2.0$ m.

\subsubsection{No Risk Zone ($|d_y| > d_{\text{safe}}$)}

When the lateral distance exceeds the safe threshold, no force is generated:
\begin{equation}
F_{\text{obstacle}} = 0
\label{eq:no_risk_force}
\end{equation}

This is the key feature enabling Nash to control the trajectory without interference.

\subsubsection{Low Risk Zone ($d_{\text{collision}} < |d_y| \leq d_{\text{safe}}$)}

Minimal exponentially-decaying force provides gentle awareness:
\begin{equation}
F_{\text{obstacle}} = 0.1 \cdot K_{\text{obs}} \cdot \exp\left(-\frac{|d_y|}{\tau_d}\right) \cdot \text{sign}(d_y)
\label{eq:low_risk_force}
\end{equation}

where $K_{\text{obs}} = 150$ N and $\tau_d = 20$ m.

\subsubsection{High Risk Zone ($|d_y| \leq d_{\text{collision}}$)}

When collision risk is high, force scales with danger level:

\begin{equation}
\eta_{\text{danger}} = \min\left(2.0, \frac{d_{\text{collision}} - |d_y|}{d_{\text{collision}}}\right)
\label{eq:danger_level}
\end{equation}

Longitudinal overlap is considered:
\begin{equation}
\eta_{\text{overlap}} = \begin{cases}
1.5 & |d_x| < d_{x,\text{threshold}} \text{ (direct overlap)} \\
\max(0.3, 1 - \frac{|d_x| - d_{x,\text{threshold}}}{d_{x,\text{threshold}}}) & \text{otherwise}
\end{cases}
\label{eq:overlap_factor}
\end{equation}

where $d_{x,\text{threshold}} = 10$ m.

The total obstacle force uses smooth saturation:
\begin{equation}
F_{\text{obstacle}} = K_{\text{obs}} \cdot \tanh\left(\frac{\eta_{\text{danger}} \cdot \eta_{\text{overlap}} \cdot K_{\text{obs}}}{K_{\text{scale}}}\right) \cdot \text{sign}(d_y)
\label{eq:high_risk_force}
\end{equation}

where $K_{\text{scale}} = 5.0$ determines the saturation rate.

\subsection{Road Boundary Forces}

Repulsive forces prevent the vehicle from leaving the road:

\begin{equation}
F_{\text{boundary}} = K_b \cdot \tanh\left(\frac{1/d_{\text{boundary}}}{K_{b,\text{scale}}}\right) \cdot \text{sign}(\text{push direction})
\label{eq:boundary_force}
\end{equation}

where $d_{\text{boundary}}$ is distance to road edge, $K_b = 150$ N, and $K_{b,\text{scale}} = 2.0$. Boundary forces activate when $d_{\text{boundary}} < 3.0$ m.

\subsection{Total Lateral Force}

The complete lateral safety force combines obstacle and boundary contributions:

\begin{equation}
F_{\text{lateral}} = \sum_{i=1}^{N_{\text{obs}}} F_{\text{obstacle},i} + F_{\text{boundary}}
\label{eq:total_lateral}
\end{equation}

In the FOLLOWING phase, a soft transition is applied:
\begin{equation}
F_{\text{final}} = F_{\text{lateral}} \cdot \min\left(1.0, \left(\frac{|y_{\text{error}}|}{\gamma_y \cdot W_{\text{lane}}}\right)^2\right)
\label{eq:lateral_soft_transition}
\end{equation}

Output filtering ensures smooth commands:
\begin{equation}
F_{\text{output}}[k] = \alpha_f \cdot F_{\text{final}}[k] + (1 - \alpha_f) \cdot F_{\text{output}}[k-1]
\label{eq:lateral_filter}
\end{equation}

with $\alpha_f = 0.3$ and saturation at $\pm 500$ N.

\section{Integration with Nash Equilibrium Control}

\subsection{Authority Allocation Mechanism}

The safety field force directly influences the Nash equilibrium through the authority allocation mechanism. The authority ratio $\lambda$ is computed from the field force using a lookup table derived from Li et al. \cite{li_shared_2019}:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Force [N]} & \textbf{$\ln(\lambda)$} & \textbf{$\lambda$} & \textbf{System Authority [\%]} \\
\hline
$-400$ & $-4.27$ & 0.014 & 1.4 \\
$-200$ & $-3.56$ & 0.028 & 2.7 \\
$0$ & $-1.78$ & 0.169 & 14.5 \\
$100$ & $-0.83$ & 0.436 & 30.4 \\
$200$ & $0.00$ & 1.000 & 50.0 \\
$300$ & $0.63$ & 1.878 & 65.3 \\
$500$ & $2.21$ & 9.116 & 90.1 \\
$800$ & $4.23$ & 68.717 & 98.6 \\
\hline
\end{tabular}
\caption{Authority allocation mapping from safety field force}
\label{tab:authority_mapping}
\end{table}

The system authority $\alpha$ is computed from $\lambda$:
\begin{equation}
\alpha = \frac{\lambda}{1 + \lambda}
\label{eq:authority_alpha}
\end{equation}

This creates the control loop:
\begin{equation}
\text{Safety Field} \xrightarrow{F} \text{Authority Allocator} \xrightarrow{\lambda} \text{Nash Weights} \xrightarrow{u_1, u_2} \text{Shared Control} \xrightarrow{u_{\text{shared}}} \text{Vehicle}
\label{eq:control_loop}
\end{equation}

\subsection{Separation of Concerns}

The architecture maintains a clear separation between the three components. The \textbf{Nash Equilibrium} enables optimal trajectory tracking via cost-function optimization, in which both longitudinal (gap and velocity tracking) and lateral (position and heading tracking) controllers share the same Nash framework within DMPC. The \textbf{Safety Field} handles collision avoidance via repulsive forces, generating force only when collision risk exists, thereby enabling Nash to operate without interference when the vehicle is safe. The \textbf{Phase Detection} handles context awareness, distinguishing active merging from steady-state following and enabling different control strategies for different situations.

This separation ensures that normal operation relies on Nash for smooth, optimal control, that safety intervention occurs only when genuinely needed, and that transitions between modes are smooth and predictable.

\section{Computational Considerations}

\subsection{Complexity Analysis}

The \textbf{Longitudinal Safety Field} has time complexity $O(1)$ since a constant number of vehicles are considered. The update rate is 10 Hz, matching the longitudinal controller, and the typical computation time is under 1 ms.

The \textbf{Lateral Safety Field} has time complexity $O(N_{\text{obs}})$ where $N_{\text{obs}}$ is the number of obstacles. The update rate is 50 Hz, matching the lateral controller, with typical computation time under 0.5 ms for 3-5 obstacles.

\subsection{Numerical Stability}

Several measures ensure numerical stability. Epsilon regularization adds $\epsilon = 0.1$ m to all distance denominators. Force saturation through defined limits prevents unbounded outputs. Low-pass filtering smooths parameter and force transitions. Tanh saturation provides natural, smooth limiting for high forces.

\section{Summary}

This chapter presented the safety field formulations for both longitudinal and lateral control. Six key contributions emerge from this work.

First, the \textbf{Pure Repulsive Design} ensures that forces are generated only when collision risk exists, specifically when $e_{\text{gap}} < 0$ for longitudinal control and $d_y < d_{\text{safe}}$ for lateral control. This enables Nash to control trajectories without interference when the vehicle is safe.

Second, the \textbf{Dynamic Phase Detection} uses state-based rather than timer-based phase transitions with hysteresis to prevent oscillations and enable context-appropriate control responses.

Third, the \textbf{Soft Transition Function} provides quadratic scaling in the FOLLOWING phase, ensuring smooth force reduction as errors decrease.

Fourth, the \textbf{Bidirectional Longitudinal Field} employs asymmetric leader/follower weighting with $w_f \in [0.2, 0.5]$ to reflect CACC information flow characteristics.

Fifth, the \textbf{Collision-Based Lateral Field} employs a two-threshold system that distinguishes ``safe, aware,'' and ``danger'' zones and elicits appropriate force responses.

Sixth, \textbf{Target Locking} ensures that merge targets are locked at trigger time to prevent target switching during maneuvers.

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Parameter} & \textbf{Longitudinal} & \textbf{Lateral} \\
\hline
Base safety radius $s_{\text{base}}$ & 10 m & -- \\
Base obstacle mass $M_{\text{base}}$ & 400 kg & -- \\
Distance decay $\tau_d$ & 15 m & 20 m \\
Filter coefficient $\alpha_f$ & 0.2 & 0.3 \\
Force gain $K$ & -- & 150 N \\
Max force & 800 N & 500 N \\
Safe distance $d_{\text{safe}}$ & -- & 3.0 m \\
Collision threshold $d_{\text{collision}}$ & -- & 2.0 m \\
Follower weight $w_f$ & 0.2--0.5 & -- \\
\hline
\end{tabular}
\caption*{\textbf{Phase Detection (Both Controllers)}}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Parameter} & \textbf{Longitudinal} & \textbf{Lateral} \\
\hline
FOLLOWING entry (gap/y error) & 15\% & 15\% $\times W_{\text{lane}}$ \\
FOLLOWING entry (velocity/$\psi$) & 5\% & 0.05 rad \\
FOLLOWING exit (hysteresis) & 25\% / 10\% & 25\% / 0.10 rad \\
Transition time $T_{\text{stable}}$ & 5 s & 5 s \\
\hline
\end{tabular}
\caption{Summary of safety field parameters}
\label{tab:safety_params_summary}
\end{table}

Chapter 4 describes the complete Nash game formulation, the DPP-compliant solver architecture, and the authority allocation mechanism.

%--------------------------------------------------------------
% CHAPTER 4: GAME-THEORETIC FRAMEWORK — CORRECTED VERSION V2
%--------------------------------------------------------------
% ================================================================
%  CHANGE LOG  (Thesis-System Alignment Validator)
%  Date: 2026-02-10
%  Compared: hslu_thesis.tex (a4f22f8) vs codebase (13d4577, cd263fa,
%            96193265, 72ded07, 8102453, 11d8e97)
% ================================================================
%
%  V2 ADDITIONS over V1:
%  [NEW-1] Full lateral controller formulation with bicycle model,
%          separate weight tables, driver-type modifiers, heading
%          constraint derivation.
%  [NEW-2] Comprehensive academic citations using existing .bib keys.
%  [NEW-3] Explicit comparison tables between longitudinal and lateral.
%  [NEW-4] Lateral authority allocator (simpler sigmoid + rate limit).
%  [NEW-5] Lateral reference generators (quintic system, cubic human).
%
%  All previous V1 corrections [C1]-[C17] remain applied.
% ================================================================

\chapter{Game-Theoretic Framework}
\label{ch:game_theory}

This chapter presents the complete game-theoretic formulation for shared control during platoon merging. The framework applies to both longitudinal control (acceleration) and lateral control (steering), with each domain requiring its own state-space model, cost function weights, and authority allocation strategy. Section~\ref{sec:nash_formulation} introduces the Nash game structure. Section~\ref{sec:dmpc} describes the Distributed Model Predictive Control (DMPC) prediction framework for both domains. Section~\ref{sec:cost_functions} defines the cost functions, including the cross-coupling terms that enable cooperation. Section~\ref{sec:authority_allocation} presents the dynamic authority allocation mechanism. Section~\ref{sec:solution_algorithm} details the DPP-compliant stacked Quadratic Programming solution. Section~\ref{sec:reference_generation} describes the reference trajectory generation for both players. Section~\ref{sec:comparison} provides a direct comparison between the longitudinal and lateral implementations.

% ===================================================================
\section{Nash Game Formulation}
\label{sec:nash_formulation}
% ===================================================================

\subsection{Two-Player Non-Cooperative Game}

The shared control problem is formulated as a non-cooperative differential game between two players, following the framework of Li et al.~\cite{li_shared_2019}. Player~1 is the autonomous system, and Player~2 is the human driver. Both players operate on the same vehicle, applying their respective control inputs(longitudinal acceleration or steering angle) to a shared dynamic system.

Although the formulation is non-cooperative in the game-theoretic sense, cooperative behavior emerges through two mechanisms. The first is the cross-coupling cost terms $S_1$ and $S_2$, which penalize each player for the other player's control effort. The second is the dynamic authority allocation parameter $\lambda(k)$, which scales the human driver's cost function based on the current risk level assessed through the driving safety field~\cite{wang_driving_2015, wang_driving_2016}.

A central design principle is that each player tracks its own reference trajectory independently. The autonomous system tracks the safety-optimal reference $\mathbf{r}_1$, while the human driver tracks their comfort-oriented reference $\mathbf{r}_2$. No blending of references occurs within the Nash game; coordination between players arises solely from the cost function structure and the post-optimization authority blending of the resulting control inputs:
\begin{equation}
u_{\text{shared}}[k] = \alpha[k] \cdot u_1^*[k] + (1 - \alpha[k]) \cdot u_2^*[k]
\label{eq:shared_control_ch4}
\end{equation}
where $\alpha[k] = \lambda[k] / (1 + \lambda[k])$ converts the authority ratio to a blending weight~\cite{li_shared_2019}.

\subsection{Nash Equilibrium Definition}

A strategy pair $(D_1^*, D_2^*)$ constitutes a Nash equilibrium if neither player can unilaterally improve their cost by deviating~\cite{jond_connected_2023}:
\begin{align}
J_1(D_1^*, D_2^*) &\leq J_1(D_1, D_2^*) \quad \forall D_1 \label{eq:nash_def_1}\\
J_2(D_1^*, D_2^*) &\leq J_2(D_1^*, D_2) \quad \forall D_2 \label{eq:nash_def_2}
\end{align}

Unlike centralized optimization, which minimizes a single combined objective, the Nash equilibrium preserves individual objectives while achieving coordination through the dynamic coupling via $\lambda[k]$ and the cross-coupling weights $S_1$, $S_2$~\cite{li_shared_2019}.

\subsection{Game Structure per Control Cycle}

At each control cycle $k$, the game proceeds as follows:
\begin{enumerate}
\item Both players observe the current state $\mathbf{x}[k]$.
\item The safety field computes the risk force $F_{\text{total}}[k]$ (Chapter~3, based on~\cite{wang_driving_2015, wang_driving_2016, song_vehicle_2013}).
\item The authority allocator maps the force to an authority ratio $\lambda[k]$.
\item Both players' optimization problems are solved simultaneously as a single stacked QP.
\item The shared control is computed via Eq.~\eqref{eq:shared_control_ch4}.
\end{enumerate}

This procedure applies identically to both the longitudinal and lateral controllers, differing only in the state-space model, weight matrices, and constraint values.

% ===================================================================
\section{Distributed Model Predictive Control Framework}
\label{sec:dmpc}
% ===================================================================

\subsection{Longitudinal Dynamics}
\label{sec:longitudinal_dynamics}

The longitudinal dynamics are described by a double-integrator model with state $\mathbf{x} = [p, v]^T$ (position and velocity) and control input $u$ (acceleration). The discrete-time matrices are:
\begin{equation}
\mathbf{A}_{\text{long}} = \begin{bmatrix} 1 & T_s \\ 0 & 1 \end{bmatrix}, \quad
\mathbf{B}_{\text{long}} = \begin{bmatrix} T_s^2/2 \\ T_s \end{bmatrix}, \quad
\mathbf{C}_{\text{long}} = \mathbf{I}_2
\label{eq:long_ss}
\end{equation}

Both players apply acceleration to the same vehicle, so $\mathbf{B}_1 = \mathbf{B}_2 = \mathbf{B}_{\text{long}}$. The output is $\mathbf{z} = [p, v]^T$ with $n_x = 2$ states and $n_z = 2$ outputs.

\subsection{Lateral Dynamics: Bicycle Model}
\label{sec:lateral_dynamics}

The lateral dynamics use a linear bicycle model~\cite{rajamani_vehicle_2005} with state $\mathbf{x} = [y, \dot{y}, \psi, \dot{\psi}]^T$ (lateral position, lateral velocity, heading angle, yaw rate) and control input $\delta$ (front-wheel steering angle). The continuous-time state-space matrices are:
\begin{equation}
\mathbf{A}_c = \begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & -\frac{C_f + C_r}{m v_x} & \frac{C_f + C_r}{m} & -\frac{L_f C_f - L_r C_r}{m v_x} \\
0 & 0 & 0 & 1 \\
0 & -\frac{L_f C_f - L_r C_r}{I_z v_x} & \frac{L_f C_f - L_r C_r}{I_z} & -\frac{L_f^2 C_f + L_r^2 C_r}{I_z v_x}
\end{bmatrix}
\label{eq:Ac_bicycle}
\end{equation}
\begin{equation}
\mathbf{B}_c = \begin{bmatrix} 0 \\ C_f / m \\ 0 \\ L_f C_f / I_z \end{bmatrix}
\label{eq:Bc_bicycle}
\end{equation}

where $C_f$ and $C_r$ are the front and rear cornering stiffness coefficients, $L_f$ and $L_r$ are the distances from the center of gravity to the front and rear axles, $m$ is the vehicle mass, $I_z$ is the yaw moment of inertia, and $v_x$ is the longitudinal velocity (assumed constant within each prediction horizon)~\cite{rajamani_vehicle_2005, fernandez_vehicle_nodate}.

Discretization is performed using the matrix exponential method~\cite{rajamani_vehicle_2005}:
\begin{equation}
\begin{bmatrix} \mathbf{A}_{\text{lat}} & \mathbf{B}_{\text{lat}} \\ \mathbf{0} & \mathbf{I} \end{bmatrix}
= \exp\!\left( \begin{bmatrix} \mathbf{A}_c & \mathbf{B}_c \\ \mathbf{0} & \mathbf{0} \end{bmatrix} T_s \right)
\label{eq:zoh_discretization}
\end{equation}

The output matrix selects the lateral position and heading angle:
\begin{equation}
\mathbf{C}_{\text{lat}} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 \end{bmatrix}
\label{eq:C_lateral}
\end{equation}

yielding $\mathbf{z} = [y, \psi]^T$ with $n_x = 4$ states and $n_z = 2$ outputs. As in the longitudinal case, both players apply steering to the same vehicle: $\mathbf{B}_1 = \mathbf{B}_2 = \mathbf{B}_{\text{lat}}$.

The vehicle parameters used in the bicycle model are summarized in Table~\ref{tab:vehicle_params}.

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Parameter} & \textbf{Symbol} & \textbf{Value} \\
\hline
Vehicle mass & $m$ & 1500 kg \\
Yaw moment of inertia & $I_z$ & 2500 kg$\cdot$m$^2$ \\
Wheelbase & $L$ & 2.7 m \\
CG to front axle & $L_f$ & 1.2 m \\
CG to rear axle & $L_r$ & 1.5 m \\
Front cornering stiffness & $C_f$ & 80,000 N/rad \\
Rear cornering stiffness & $C_r$ & 80,000 N/rad \\
Nominal longitudinal velocity & $v_x$ & 20 m/s \\
\hline
\end{tabular}
\caption{Vehicle parameters for the bicycle model~\cite{rajamani_vehicle_2005}}
\label{tab:vehicle_params}
\end{table}

\subsection{Multi-Step Prediction and Compact Form}

For both domains, the system output over the prediction horizon $N_p$ is written in compact form as:
\begin{equation}
\mathbf{Z}[k] = \mathbf{U} \mathbf{x}[k] + \mathbf{H} D_1 + \mathbf{H} D_2
\label{eq:compact_prediction}
\end{equation}
where $\mathbf{U} \in \mathbb{R}^{n_z N_p \times n_x}$ is the free response matrix and $\mathbf{H} \in \mathbb{R}^{n_z N_p \times N_u}$ is the forced response matrix. Since $\mathbf{B}_1 = \mathbf{B}_2$ in both domains, the forced response matrices are identical: $\mathbf{H}_1 = \mathbf{H}_2 \equiv \mathbf{H}$.

The free response matrix is:
\begin{equation}
\mathbf{U} = \begin{bmatrix} \mathbf{C} \mathbf{A} \\ \mathbf{C} \mathbf{A}^2 \\ \vdots \\ \mathbf{C} \mathbf{A}^{N_p} \end{bmatrix}
\label{eq:U_matrix}
\end{equation}

The forced response matrix $\mathbf{H}$ has a lower-triangular Toeplitz structure:
\begin{equation}
\mathbf{H} = \begin{bmatrix}
\mathbf{C} \mathbf{B} & \mathbf{0} & \cdots & \mathbf{0} \\
\mathbf{C} \mathbf{A} \mathbf{B} & \mathbf{C} \mathbf{B} & \cdots & \mathbf{0} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{C} \mathbf{A}^{N_p-1} \mathbf{B} & \mathbf{C} \mathbf{A}^{N_p-2} \mathbf{B} & \cdots & \mathbf{C} \mathbf{A}^{N_p-N_u} \mathbf{B}
\end{bmatrix}
\label{eq:H_matrix}
\end{equation}

The dimensions of $\mathbf{U}$ and $\mathbf{H}$ differ between the two domains due to different state and output dimensions (longitudinal: $n_x = n_z = 2$; lateral: $n_x = 4$, $n_z = 2$), but the algebraic structure is identical.

% ===================================================================
\section{Cost Function Formulation}
\label{sec:cost_functions}
% ===================================================================

\subsection{General Quadratic Cost Structure with Cross-Coupling}

Following Li et al.~\cite{li_shared_2019}, each player minimizes a quadratic cost over the prediction horizon that includes cross-coupling terms penalizing the other player's control effort:
\begin{align}
J_1 &= \sum_{j=0}^{N_p-1} \| \mathbf{e}_1[k+j] \|_{Q_1}^2 + \sum_{j=0}^{N_u-1} \left( R_1 \, u_1[k+j]^2 + S_1 \, u_2[k+j]^2 \right) \label{eq:cost_player1}\\
J_2 &= \sum_{j=0}^{N_p-1} \| \mathbf{e}_2[k+j] \|_{Q_2(\lambda)}^2 + \sum_{j=0}^{N_u-1} \left( R_2 \, u_2[k+j]^2 + S_2 \, u_1[k+j]^2 \right) \label{eq:cost_player2}
\end{align}
where $\mathbf{e}_i[k+j] = \mathbf{r}_i[k+j] - \mathbf{z}[k+j]$ is the tracking error for player $i$, $Q_i$ is the output tracking weight matrix, $R_i$ is the own control effort weight, and $S_i$ is the cross-coupling weight penalizing the other player's control effort.

The authority ratio $\lambda$ enters through Player~2's tracking weight:
\begin{equation}
Q_2(\lambda[k]) = \lambda[k] \cdot Q_1
\label{eq:Q2_coupling}
\end{equation}

When $\lambda$ is low (safe conditions), Player~2's tracking penalty is small, giving the human more freedom. When $\lambda$ is high (dangerous conditions), Player~2 is strongly penalized for deviating from their reference~\cite{li_shared_2019}.

\subsection{Longitudinal Cost Function Weights}

For the longitudinal controller, the output weight matrix tracks gap position and velocity:
\begin{equation}
Q_{1}^{\text{long}} = \begin{bmatrix} Q_{1,p} & 0 \\ 0 & Q_{1,v} \end{bmatrix} = \begin{bmatrix} 2500 & 0 \\ 0 & 50 \end{bmatrix}
\label{eq:Q1_long}
\end{equation}

The position-tracking weight $Q_{1,p} = 2500$ is substantially higher than the velocity-tracking weight $Q_{1,v} = 50$, thereby implementing a position-dominant tuning strategy. In platoon merging, the primary objective is to close the gap to the correct position, and velocity matching follows naturally. The control effort weights are:
\begin{equation}
R_1^{\text{long}} = R_2^{\text{long}} = S_1^{\text{long}} = S_2^{\text{long}} = 800
\label{eq:RS_long}
\end{equation}

\subsection{Lateral Cost Function Weights}

For the lateral controller, the output weight matrix tracks lateral position and heading angle:
\begin{equation}
Q_{1}^{\text{lat}} = \begin{bmatrix} Q_{1,y} & 0 \\ 0 & Q_{1,\psi} \end{bmatrix} = \begin{bmatrix} 10 & 0 \\ 0 & 10{,}000 \end{bmatrix}
\label{eq:Q1_lat}
\end{equation}

The heading weight $Q_{1,\psi} = 10{,}000$ is three orders of magnitude larger than the lateral position weight $Q_{1,y} = 10$. This heading-dominant tuning reflects a fundamental principle: the vehicle must first stabilize its heading angle before correcting its lateral position. An unstable heading during a lane change results in dangerous oscillations, whereas a slightly longer lateral correction is acceptable.

The control effort weights for the lateral controller are:
\begin{equation}
R_1^{\text{lat}} = R_2^{\text{lat}} = 1{,}000{,}000, \quad S_1^{\text{lat}} = S_2^{\text{lat}} = 200{,}000
\label{eq:RS_lat}
\end{equation}

These weights are orders of magnitude larger than the longitudinal weights because the control input is a steering angle (radians, typically $|\delta| \ll 0.01$~rad) rather than acceleration (m/s$^2$, typically $|u| \sim 1$--$2$~m/s$^2$). The high $R/Q_y$ ratio of $100{,}000$ ensures realistic, small steering corrections that satisfy passenger comfort constraints~\cite{rajamani_vehicle_2005}.

\subsection{Scale Separation Between Domains}

The difference in weight magnitudes between the longitudinal and lateral controllers arises from the physical scales of the respective control inputs. For the longitudinal domain, typical accelerations are $\sim 2$~m/s$^2$, while for the lateral domain, typical steering angles are $\sim 0.01$~rad ($\approx 0.6\SI{2}{\degree}$). To achieve similar relative penalties, the control effort weights must scale inversely with the square of the typical input magnitude. This is why $R^{\text{lat}} / R^{\text{long}} \approx 1250$, roughly matching $(2/0.01)^2 \cdot (800 / 1{,}000{,}000)^{-1}$.

Direct copying of weight values between domains without this scaling would produce either negligible control effort (if longitudinal weights were used for lateral) or excessive, saturating control (if lateral weights were used for longitudinal).

\subsection{The \texorpdfstring{$S = R$}{S = R} Cooperation Principle and Its Lateral Variant}
\label{sec:cooperation_principle}

A fundamental insight of this research is that the cross-coupling weights $S_i$ determine the nature of the Nash equilibrium. In the stacked QP formulation (Section~\ref{sec:solution_algorithm}), the cross-coupling weights appear in the diagonal blocks of the Hessian:
\begin{align}
\mathbf{P}_{11} &= \mathbf{H}^T \bar{Q}_1 \mathbf{H} + (R_1 + S_2) \mathbf{I}_{N_u} \label{eq:P11}\\
\mathbf{P}_{22} &= \lambda \, \mathbf{H}^T \bar{Q}_1 \mathbf{H} + (R_2 + S_1) \mathbf{I}_{N_u} \label{eq:P22}
\end{align}

Setting $S_i = R_i$ produces a symmetric penalty structure where each player equally penalizes both its own and the other's control effort:
\begin{itemize}
\item When $S < R$: each player weighs its own control cost more heavily, leading to \textit{competitive} behavior where both controllers fight each other.
\item When $S = R$: both costs are equally weighted, yielding a \textit{cooperative} equilibrium where both controllers converge smoothly.
\item When $S > R$: each player over-prioritizes the other's cost, leading to overly deferential behavior.
\end{itemize}

\paragraph{Longitudinal implementation.} The $S = R$ principle is applied directly: $R_1 = R_2 = S_1 = S_2 = 800$.

\paragraph{Lateral implementation.} A modified ratio of $S/R = 0.2$ is used: $R = 1{,}000{,}000$ and $S = 200{,}000$. This departure from $S = R$ is necessitated by the bicycle model dynamics, which are more sensitive to cross-coupling disturbances than the double-integrator longitudinal model. At $S = R$, the lateral controller exhibited oscillations in the heading angle during lane changes. The $S = 0.2 R$ ratio provides sufficient coupling for cooperative behavior while maintaining heading stability.

\subsection{Driver-Type Modifiers (Lateral Controller)}
\label{sec:driver_type}

Following Li et al.~\cite{li_shared_2019}, the lateral controller supports three driver types by modifying Player~2's cost function weights. The modifiers are applied to the base values $R_2^{\text{lat}}$, $S_2^{\text{lat}}$, and $Q_{1,y}^{\text{lat}}$:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Driver Type} & \textbf{$R_2$ Factor} & \textbf{$S_2$ Factor} & \textbf{$Q_y$ Factor} \\
\hline
Cautious   & 1.5 & 1.5 & 0.8 \\
Normal     & 1.0 & 1.0 & 1.0 \\
Aggressive & 0.6 & 0.6 & 1.3 \\
\hline
\end{tabular}
\caption{Driver-type modifiers for lateral Nash game weights}
\label{tab:driver_types}
\end{table}

A cautious driver has a higher $R_2$ (prefers gentle control), a higher $S_2$ (is more cooperative with the system), and a lower $Q_y$ (exhibits less aggressive position tracking). An aggressive driver has a lower $R_2$ (willingness to use large steering inputs), a lower $S_2$ (cooperativeness), and a higher $Q_y$ (demanding faster lane changes). These modifiers are not applied in the longitudinal controller, where driver behavior is modeled differently through the human reference trajectory.

\subsection{Compact Matrix Representation}

Using Eq.~\eqref{eq:compact_prediction}, the compact cost functions become:
\begin{align}
J_1 &= \mathbf{E}_1^T \bar{Q}_1 \mathbf{E}_1 + D_1^T \bar{R}_1 D_1 + D_2^T \bar{S}_1 D_2 \label{eq:cost_matrix_1}\\
J_2 &= \mathbf{E}_2^T \bar{Q}_2 \mathbf{E}_2 + D_2^T \bar{R}_2 D_2 + D_1^T \bar{S}_2 D_1 \label{eq:cost_matrix_2}
\end{align}
where $\bar{Q}_1 = \text{diag}(Q_1, \ldots, Q_1)$, $\bar{Q}_2 = \lambda \bar{Q}_1$, $\bar{R}_i = R_i \mathbf{I}_{N_u}$, $\bar{S}_i = S_i \mathbf{I}_{N_u}$, and $\mathbf{E}_i = \mathbf{R}_i - \mathbf{U}\mathbf{x}[k] - \mathbf{H}D_1 - \mathbf{H}D_2$.

% ===================================================================
\section{Dynamic Authority Allocation}
\label{sec:authority_allocation}
% ===================================================================

The authority ratio $\lambda[k]$ dynamically adjusts the balance between system and human control based on the assessed risk level. The longitudinal and lateral controllers use different authority allocation strategies reflecting their distinct operational requirements.

\subsection{Longitudinal Authority Allocation: Dual-Source with Hysteresis}
\label{sec:long_authority}

The longitudinal authority is computed from two independent sources, following the safety field framework of Wang et al.~\cite{wang_driving_2015, wang_driving_2016} as adapted by Li et al.~\cite{li_shared_2019}.

\subsubsection{Safety Authority via Sigmoid Mapping}

The safety field force $F_{\text{total}}[k]$ is mapped to an authority ratio through a sigmoid function:
\begin{equation}
\lambda_{\text{safety}}[k] = \lambda_{\min} + (\lambda_{\max} - \lambda_{\min}) \cdot \sigma\!\left(k_s \cdot (|F_{\text{total}}[k]| - F_{\text{mid}})\right)
\label{eq:sigmoid_authority_long}
\end{equation}
where $\sigma(x) = 1/(1 + e^{-x})$, $\lambda_{\min} = 0.1$, $\lambda_{\max} = 100$, $k_s = 0.015$, and $F_{\text{mid}} = 400$~N. This sigmoid mapping yields a continuously differentiable authority transition, unlike the discrete lookup table used by Li et al.~\cite{li_shared_2019}.

\subsubsection{Performance Authority with Hysteresis}

A performance-based authority addresses situations in which the gap error is large but the safety force is small (e.g., during initial gap closure). A hysteresis mechanism prevents oscillations at the mode boundary:
\begin{equation}
\text{Enter performance mode:} \quad |e_{\text{gap}}[k]| > d_{\text{enter}} = 3.0 \text{ m}
\label{eq:hysteresis_enter}
\end{equation}
\begin{equation}
\text{Exit performance mode:} \quad |e_{\text{gap}}[k]| < d_{\text{exit}} = 1.0 \text{ m}
\label{eq:hysteresis_exit}
\end{equation}

When in performance mode, the authority is computed as:
\begin{equation}
\lambda_{\text{perf}}[k] = 1.0 + 0.3 \bar{e} + 0.25 (|e_{\text{gap}}| - d_{\text{exit}})
\label{eq:perf_authority}
\end{equation}
where $\bar{e} = \max(0, (|e_{\text{gap}}| - d_{\text{exit}}) / (d_{\text{enter}} - d_{\text{exit}}))$. An asymmetry factor of $1.3$ is applied when $e_{\text{gap}} > 0$ (catching up is more urgent). The performance authority is bounded by $\lambda_{\text{perf}} \leq 50$.

\subsubsection{Fusion and Adaptive Smoothing}

The target authority is the maximum of the two sources:
\begin{equation}
\lambda_{\text{target}}[k] = \max\!\left(\lambda_{\text{safety}}[k], \, \lambda_{\text{perf}}[k]\right)
\label{eq:lambda_fusion}
\end{equation}

Smoothing uses an adaptive exponential moving average (EMA):
\begin{equation}
\lambda[k] = \alpha_\lambda \cdot \lambda_{\text{target}}[k] + (1 - \alpha_\lambda) \cdot \lambda[k-1]
\label{eq:lambda_smooth_long}
\end{equation}
where $\alpha_\lambda$ adapts based on the gap error:
\begin{equation}
\alpha_\lambda = \begin{cases}
0.12 & |e_{\text{gap}}| > 5.0 \text{ m} \\
0.05 + 0.07 \cdot \frac{|e_{\text{gap}}| - 2.0}{3.0} & 2.0 < |e_{\text{gap}}| \leq 5.0 \\
0.05 & |e_{\text{gap}}| \leq 2.0
\end{cases}
\label{eq:adaptive_alpha_long}
\end{equation}

\subsection{Lateral Authority Allocation: Sigmoid with Rate Limiting}
\label{sec:lat_authority}

The lateral authority allocator uses a simpler single-source design, as the lateral safety field force alone provides sufficient risk assessment during lane changes.

\subsubsection{Sigmoid Mapping}

The lateral safety force is mapped similarly to the longitudinal case, but with different parameters reflecting the lower force magnitudes typical of lateral interactions~\cite{wang_driving_2016, song_vehicle_2013}:
\begin{equation}
\lambda_{\text{lat}}[k] = \lambda_{\min} + (\lambda_{\max} - \lambda_{\min}) \cdot \sigma\!\left(k_s \cdot (|F_{\text{lat}}[k]| - F_{\text{mid}})\right)
\label{eq:sigmoid_authority_lat}
\end{equation}
with $\lambda_{\min} = 0.1$, $\lambda_{\max} = 10$, $k_s = 0.02$, and $F_{\text{mid}} = 150$~N.

The lateral authority range ($\lambda \in [0.1, 10]$) is narrower than the longitudinal range ($\lambda \in [0.1, 100]$) because excessive system authority during lane changes can produce abrupt steering corrections that compromise passenger comfort.

\subsubsection{Smoothing and Rate Limiting}

The lateral authority uses a first-order low-pass filter followed by rate limiting:
\begin{equation}
\hat{\lambda}[k] = \alpha_\lambda \cdot \lambda_{\text{target}}[k] + (1 - \alpha_\lambda) \cdot \lambda[k-1]
\label{eq:lateral_lpf}
\end{equation}
with $\alpha_\lambda = 0.02$ (very slow smoothing for comfort). The rate is then limited:
\begin{equation}
\lambda[k] = \lambda[k-1] + \text{clip}\!\left(\hat{\lambda}[k] - \lambda[k-1], \; -\Delta\lambda_{\text{down}}, \; \Delta\lambda_{\text{up}}\right)
\label{eq:lateral_rate_limit}
\end{equation}
where $\Delta\lambda_{\text{up}} = 0.02$ per step and $\Delta\lambda_{\text{down}} = 0.01$ per step. The asymmetric rate-limiting (slower release than engagement) ensures that the system does not relinquish authority prematurely following a risk event. At $T_s = 0.01$~s (lateral simulation rate), reaching maximum authority from minimum requires approximately 5 seconds.

\subsection{Conversion to Control Authority}

For both controllers, the shared control uses:
\begin{equation}
\alpha[k] = \frac{\lambda[k]}{1 + \lambda[k]}, \quad
u_{\text{shared}}[k] = \alpha[k] \cdot u_1^*[k] + (1 - \alpha[k]) \cdot u_2^*[k]
\label{eq:alpha_shared}
\end{equation}

% ===================================================================
\section{Nash Equilibrium Solution via Stacked QP}
\label{sec:solution_algorithm}
% ===================================================================

\subsection{From Best-Response to Stacked QP}

The Nash equilibrium can be derived through the best-response approach. Taking the gradient of $J_1$ with respect to $D_1$ and setting to zero:
\begin{equation}
(\mathbf{H}^T \bar{Q}_1 \mathbf{H} + \bar{R}_1) D_1 = \mathbf{H}^T \bar{Q}_1 (\mathbf{e}_1^{\text{free}} - \mathbf{H} D_2)
\label{eq:best_response_1}
\end{equation}

Similarly for Player~2:
\begin{equation}
(\mathbf{H}^T \bar{Q}_2 \mathbf{H} + \bar{R}_2) D_2 = \mathbf{H}^T \bar{Q}_2 (\mathbf{e}_2^{\text{free}} - \mathbf{H} D_1)
\label{eq:best_response_2}
\end{equation}

These coupled equations could be solved iteratively through alternating optimization~\cite{li_shared_2019}. However, to achieve DPP compliance for real-time performance, the equilibrium is reformulated as a single stacked QP over $\mathbf{u} = [D_1^T, D_2^T]^T \in \mathbb{R}^{2N_u}$:
\begin{equation}
\min_{\mathbf{u}} \; \frac{1}{2} \mathbf{u}^T \mathbf{P} \mathbf{u} + \mathbf{q}^T \mathbf{u}
\label{eq:stacked_qp}
\end{equation}

\subsection{Stacked Hessian Structure}

The Hessian $\mathbf{P} \in \mathbb{R}^{2N_u \times 2N_u}$ has the block structure:
\begin{equation}
\mathbf{P} = \begin{bmatrix} \mathbf{P}_{11} & \mathbf{P}_{12} \\ \mathbf{P}_{12}^T & \mathbf{P}_{22} \end{bmatrix}
\label{eq:P_block}
\end{equation}
with blocks given by Eqs.~\eqref{eq:P11}--\eqref{eq:P22} and the off-diagonal cross-coupling:
\begin{equation}
\mathbf{P}_{12} = c(\lambda) \cdot \mathbf{H}^T \bar{Q}_1 \mathbf{H}
\label{eq:P12_full}
\end{equation}
where $c(\lambda) = \sqrt{\min(\lambda, 1)}$ ensures positive definiteness for small $\lambda$. Without this scaling, the Schur complement condition $\mathbf{P}_{22} - \mathbf{P}_{12}^T \mathbf{P}_{11}^{-1} \mathbf{P}_{12} \succ 0$ may fail when the weakened $\mathbf{P}_{22}$ (at small $\lambda$) cannot dominate the cross-coupling.

The linear term $\mathbf{q}$ updates at each time step:
\begin{equation}
\mathbf{q} = \begin{bmatrix} -2 \, \mathbf{H}^T \bar{Q}_1 \, \mathbf{e}_1^{\text{free}} \\ -2\lambda \, \mathbf{H}^T \bar{Q}_1 \, \mathbf{e}_2^{\text{free}} \end{bmatrix}
\label{eq:q_vector}
\end{equation}

\subsection{DPP Compliance through Pre-computed Lambda Levels}

Since $\mathbf{P}$ depends on $\lambda$, DPP compliance requires pre-computing $\mathbf{P}$ for discrete $\lambda$ levels. At runtime, the closest level is selected in log-space:
\begin{equation}
\lambda_{\text{used}} = \arg\min_{\hat{\lambda} \in \Lambda} \left| \ln \hat{\lambda} - \ln \lambda[k] \right|
\label{eq:lambda_selection}
\end{equation}

For each $\hat{\lambda} \in \Lambda$, CVXPY caches the KKT factorization, and subsequent solves only require updating $\mathbf{q}$.

\paragraph{Longitudinal levels.} $\Lambda_{\text{long}} = \{0.1, 0.25, 0.5, 1.0, 2.0, 5.0, 10.0, 50.0\}$ (8 levels), covering the wide authority range $[0.1, 100]$.

\paragraph{Lateral levels.} $\Lambda_{\text{lat}} = \{0.1, 0.25, 0.5, 1.0, 2.0, 5.0, 10.0\}$ (7 levels), reflecting the narrower authority range $[0.1, 10]$.

\subsection{Positive Definiteness Guarantee}

After constructing $\mathbf{P}$ for each level, the eigenvalues are verified. If $\lambda_{\min}(\mathbf{P}) < 10^{-6}$, regularization is applied:
\begin{equation}
\mathbf{P}_{\text{reg}} = \mathbf{P} + \max(10^{-4} - \lambda_{\min}(\mathbf{P}), \; \epsilon_{\text{reg}}) \cdot \mathbf{I}_{2N_u}
\label{eq:regularization}
\end{equation}
where $\epsilon_{\text{reg}} = 10^{-5}$.

\subsection{Constraints}

\subsubsection{Longitudinal Constraints}

Input bounds enforce physical acceleration limits:
\begin{equation}
-3.5 \leq u_1 \leq 2.5 \text{ m/s}^2, \quad -4.0 \leq u_2 \leq 3.0 \text{ m/s}^2
\label{eq:long_bounds}
\end{equation}

Rate constraints limit the change per time step to ensure comfort~\cite{rajamani_vehicle_2005}:
\begin{equation}
|u_i[k+j] - u_i[k+j-1]| \leq \Delta u_{i,\max} \cdot T_s
\label{eq:long_rate}
\end{equation}
with $\Delta u_{1,\max} = 1.0$~m/s$^3$ and $\Delta u_{2,\max} = 1.5$~m/s$^3$.

\subsubsection{Lateral Constraints}

Steering angle bounds~\cite{rajamani_vehicle_2005}:
\begin{equation}
-0.4 \leq \delta_i \leq 0.4 \text{ rad} \quad (\approx \pm 23\SI{2}{\degree})
\label{eq:lat_bounds}
\end{equation}

Steering rate constraint:
\begin{equation}
|\delta_i[k+j] - \delta_i[k+j-1]| \leq \dot{\delta}_{\max} \cdot T_s
\label{eq:lat_rate}
\end{equation}
with $\dot{\delta}_{\max} = 0.5$~rad/s. This ensures smooth steering transitions consistent with passenger comfort expectations.

\subsection{Complete Algorithm}

Algorithm~\ref{alg:stacked_qp} presents the solution procedure, which is identical for both controllers, modulo the state-space model and constraint values.

\begin{algorithm}[H]
\caption{DPP-Compliant Nash Equilibrium via Stacked QP}
\label{alg:stacked_qp}
\begin{algorithmic}[1]
\State \textbf{Initialization (once):}
\State Build prediction matrices $\mathbf{U}$, $\mathbf{H}$ from $(\mathbf{A}, \mathbf{B}, \mathbf{C})$
\State Compute base Hessian $\mathbf{H}^T \bar{Q}_1 \mathbf{H}$
\For{each $\hat{\lambda} \in \Lambda$}
    \State Build $\mathbf{P}(\hat{\lambda})$ using Eqs.~\eqref{eq:P11}--\eqref{eq:P12_full}
    \State Verify $\mathbf{P} \succ 0$; regularize if needed (Eq.~\eqref{eq:regularization})
    \State Create CVXPY problem with constant $\mathbf{P}$, parametric $\mathbf{q}$
\EndFor
\State
\State \textbf{Runtime (each control cycle $k$):}
\State \textbf{Input:} $\mathbf{x}[k]$, $\mathbf{R}_1$, $\mathbf{R}_2$, $\lambda[k]$
\State Select $\lambda_{\text{used}} \gets \arg\min_{\hat{\lambda} \in \Lambda} |\ln \hat{\lambda} - \ln \lambda[k]|$
\State Compute free errors: $\mathbf{e}_i^{\text{free}} = \mathbf{R}_i - \mathbf{U} \mathbf{x}[k]$
\State Update $\mathbf{q}$ via Eq.~\eqref{eq:q_vector}
\State Solve cached QP for $\lambda_{\text{used}}$ with warm start
\State Extract first controls: $u_1^*[k]$, $u_2^*[k]$
\State \Return $(u_1^*[k], u_2^*[k])$
\end{algorithmic}
\end{algorithm}

% ===================================================================
\section{Reference Trajectory Generation}
\label{sec:reference_generation}
% ===================================================================

\subsection{Longitudinal References}

\subsubsection{System Reference (Player 1)}

The system reference maintains a safe following distance using the Constant Time Gap (CTG) spacing policy~\cite{rajamani_vehicle_2005}:
\begin{equation}
d_{\text{des}}[k] = d_0 + h \cdot v_{\text{ego}}[k]
\label{eq:ctg_spacing_v1}
\end{equation}
where $d_0 = 5$~m is the standstill distance and $h = 1.0$~s is the time headway. The reference over the prediction horizon is:
\begin{align}
p_{\text{ref},1}[k+j] &= p_{\text{leader}}[k+j] - d_{\text{des}}[k+j] \label{eq:long_ref_pos}\\
v_{\text{ref},1}[k+j] &= v_{\text{leader}}[k+j] \label{eq:long_ref_vel}
\end{align}

The leader's future trajectory is predicted assuming constant velocity, consistent with the IDM car-following model assumptions~\cite{treiber_congested_2000, treiber_traffic_2013}.

\subsubsection{Human Reference (Player 2)}

The human driver's longitudinal reference is generated by simulating the vehicle's behavior under platoon control for $N_p$ steps using a deep-copy forward simulation at the faster internal rate. This approach generates a realistic prediction of human intent from current conditions, consistent with human-driver modeling practices.

\subsection{Lateral References}
\label{sec:lateral_references}

The lateral reference trajectories define smooth paths for the lane change maneuver. Both references are planned once at the start of the lane change and then tracked based on elapsed time, preventing oscillations caused by replanning from the current position.

\subsubsection{System Reference: Quintic Polynomial}

The system generates a quintic (5th-order) polynomial trajectory for maximum smoothness~\cite{gu_toward_2014}:
\begin{equation}
y_{\text{ref},1}(\tau) = y_0 + \Delta y \cdot \left(10\tau^3 - 15\tau^4 + 6\tau^5\right)
\label{eq:quintic_traj}
\end{equation}
where $\tau = t / T_{\text{lc}} \in [0, 1]$ is the normalized time, $y_0$ is the starting lateral position, $\Delta y$ is the lane change distance, and $T_{\text{lc}}$ is the lane change duration.

The quintic polynomial has zero velocity and acceleration at both endpoints ($\dot{y}(0) = \dot{y}(T_{\text{lc}}) = 0$, $\ddot{y}(0) = \ddot{y}(T_{\text{lc}}) = 0$), ensuring smooth entry and exit from the lane change maneuver.

\paragraph{Heading constraint on $T_{\text{lc}}$} A critical requirement is that the heading angle remains below a threshold throughout the maneuver. Since $\psi \approx \dot{y} / v_x$ for small angles~\cite{rajamani_vehicle_2005}, the maximum heading occurs at $\tau = 0.5$:
\begin{equation}
\dot{y}_{\max} = \frac{1.875 \, |\Delta y|}{T_{\text{lc}}}
\label{eq:ydot_max_quintic}
\end{equation}

For $\psi < \psi_{\max}$, the minimum lane change duration must satisfy:
\begin{equation}
T_{\text{lc}} \geq \frac{1.875 \, |\Delta y|}{v_x \tan(\psi_{\max})}
\label{eq:Tlc_constraint}
\end{equation}

With $\psi_{\max} = 1.8\SI{2}{\degree}$ (providing margin below the \SI{2}{\degree} requirement), $|\Delta y| = 3.5$~m (one lane width), and $v_x = 20$~m/s, this yields $T_{\text{lc}} \geq 10.4$~s. The implementation uses $T_{\text{lc}} = 14$~s as the base duration, which is dynamically increased if the heading constraint requires it.

The heading reference is set to zero throughout: $\psi_{\text{ref},1} = 0$.

\subsubsection{Human Reference: Cubic Polynomial}

The human driver's reference uses a cubic (3rd-order) polynomial, reflecting the tendency of human drivers to execute lane changes more directly with less emphasis on smoothness at the endpoints~\cite{gu_toward_2014, hoffmann_autonomous_2007}:
\begin{equation}
y_{\text{ref},2}(\tau) = y_0 + \Delta y \cdot \left(3\tau^2 - 2\tau^3\right)
\label{eq:cubic_traj}
\end{equation}

The cubic polynomial has zero velocity at the endpoints but non-zero acceleration, producing a sharper transition. The heading constraint is similarly enforced:
\begin{equation}
T_{\text{lc}} \geq \frac{1.5 \, |\Delta y|}{v_x \tan(\psi_{\max})}
\label{eq:Tlc_constraint_cubic}
\end{equation}

The cubic coefficient (1.5 vs.\ 1.875 for quintic) means the human reference allows shorter lane change durations for the same heading constraint. Base durations depend on driver type: 14~s (cautious), 12~s (normal), 10~s (aggressive).

\subsection{Phase-Dependent Reference Selection}

Both lateral reference generators operate in five phases synchronized with the safety field:
\begin{enumerate}
\item \textbf{CRUISE}: Reference at current lane position.
\item \textbf{GAP\_SEARCH}: Gradual reference shift begins.
\item \textbf{LANE\_CHANGE}: Full polynomial trajectory tracking.
\item \textbf{LANE\_KEEPING}: Reference at target lane.
\item \textbf{FOLLOWING}: Reference at target lane (longitudinal control dominant).
\end{enumerate}

Phase transitions are detected using the criteria from the MOBIL lane change model~\cite{kesting_general_2007, kesting_mobil_nodate} and the lateral safety field (Chapter~3).

% ===================================================================
\section{Longitudinal vs.\ Lateral: Comparison Summary}
\label{sec:comparison}
% ===================================================================

Table~\ref{tab:comparison} summarizes the key differences between the two controller implementations.

\begin{table}[ht]
\centering
\small
\begin{tabular}{|l|c|c|}
\hline
\textbf{Feature} & \textbf{Longitudinal} & \textbf{Lateral} \\
\hline
Plant model & Double integrator & Bicycle model~\cite{rajamani_vehicle_2005} \\
State dimension $n_x$ & 2 & 4 \\
Output dimension $n_z$ & 2 & 2 \\
Control input & Acceleration [m/s$^2$] & Steering angle [rad] \\
\hline
$Q_1$ diagonal & [2500, 50] & [10, 10000] \\
$R_1 = R_2$ & 800 & 1,000,000 \\
$S_1 = S_2$ & 800 ($S = R$) & 200,000 ($S = 0.2R$) \\
\hline
$\lambda$ range & $[0.1, 100]$ & $[0.1, 10]$ \\
$|\Lambda|$ & 8 levels & 7 levels \\
Authority sources & Safety + Performance & Safety only \\
Smoothing & Adaptive EMA & Fixed EMA + rate limit \\
\hline
Input bounds & $[-3.5, 2.5]$ m/s$^2$ & $\pm 0.4$ rad \\
Rate limit & 1.0 / 1.5 m/s$^3$ & 0.5 rad/s \\
\hline
System ref.\ & CTG spacing~\cite{rajamani_vehicle_2005} & Quintic polynomial~\cite{gu_toward_2014} \\
Human ref.\ & Forward simulation & Cubic polynomial \\
Driver types & Via reference only & Via $R_2$, $S_2$, $Q_y$ modifiers \\
\hline
OSQP tol. & $10^{-4}$ & $10^{-3}$ \\
OSQP max iter. & 1000 & 200 \\
Typical solve time & 2--3 ms & 2--3 ms \\
\hline
\end{tabular}
\caption{Comparison of longitudinal and lateral Nash equilibrium implementations}
\label{tab:comparison}
\end{table}

% ===================================================================
\section{Summary}
\label{sec:ch4_summary}
% ===================================================================

This chapter presented the complete game-theoretic framework for shared control during platoon merging in both the longitudinal and lateral domains. The Nash game is formulated with cross-coupling cost terms ($S_1$, $S_2$) that promote cooperative equilibria. The authority ratio $\lambda$ dynamically scales the human's cost based on risk assessed through the driving safety field~\cite{wang_driving_2015, wang_driving_2016}. The key methodological contributions are:
\begin{enumerate}
\item A DPP-compliant stacked QP formulation that solves the Nash equilibrium in approximately 2--3~ms, a 20- to 30-fold improvement over iterative best-response methods~\cite{li_shared_2019}.
\item The $S = R$ cooperation principle for the longitudinal domain and its adapted $S = 0.2R$ variant for the lateral domain, providing a principled approach to tuning cross-coupling weights.
\item Dual-source authority allocation combining sigmoid-based safety authority~\cite{wang_driving_2016} with hysteresis-based performance authority for the longitudinal controller.
\item Heading-constrained reference trajectories that analytically guarantee the lane change satisfies $|\psi| < \psi_{\max}$ throughout the maneuver.
\item Driver-type modifiers in the lateral controller that adjust the Nash game weights to model cautious, normal, and aggressive driving styles~\cite{li_shared_2019}.
\end{enumerate}

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|}
\hline
\textbf{Parameter} & \textbf{Longitudinal} & \textbf{Lateral} \\
\hline
Prediction horizon $N_p$ & 20 (2.0 s) & 20 (2.0 s) \\
Control horizon $N_u$ & 10 (1.0 s) & 10 (1.0 s) \\
Time step $T_s$ & 0.1 s & 0.1 s \\
\hline
$Q_{1,1}$ (pos / $y$) & 2500 & 10 \\
$Q_{1,2}$ (vel / $\psi$) & 50 & 10,000 \\
$R_1 = R_2$ & 800 & 1,000,000 \\
$S_1 = S_2$ & 800 & 200,000 \\
\hline
$\lambda_{\min}$ / $\lambda_{\max}$ & 0.1 / 100 & 0.1 / 10 \\
Sigmoid $k_s$ & 0.015 & 0.02 \\
Sigmoid $F_{\text{mid}}$ & 400 N & 150 N \\
$\alpha_{\text{base}}$ / $\alpha_{\text{fast}}$ & 0.05 / 0.12 & 0.02 (fixed) \\
Hysteresis & $d_{\text{enter}}=3$m, $d_{\text{exit}}=1$m & N/A \\
Rate limit & N/A & $+0.02$, $-0.01$ per step \\
\hline
Regularization $\epsilon_{\text{reg}}$ & $10^{-5}$ & $10^{-5}$ \\
OSQP $\epsilon_{\text{abs}}$, $\epsilon_{\text{rel}}$ & $10^{-4}$ & $10^{-3}$ \\
OSQP max iter. & 1000 & 200 \\
\hline
\end{tabular}
\caption{Complete parameter summary for both Nash equilibrium solvers}
\label{tab:all_parameters}
\end{table}

%--------------------------------------------------------------
% BIBLIOGRAPHY 
%--------------------------------------------------------------

\printbibliography

%--------------------------------------------------------------
% APPENDIX
%--------------------------------------------------------------
\appendix

\chapter{Python Implementation}

The complete Python implementation is available at: \texttt{[Repository link]}

\textbf{Key modules:}
\begin{itemize}
\item \texttt{longitudinal\_nash\_solver.py}: Nash equilibrium solver with DMPC
\item \texttt{longitudinal\_safety\_field.py}: Bidirectional safety field computation
\item \texttt{longitudinal\_authority\_allocator.py}: Dynamic authority allocation
\item \texttt{main\_with\_nash.py}: Complete system integration
\end{itemize}

\end{document}











